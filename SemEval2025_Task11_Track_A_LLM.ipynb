{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- Finetune Llama 3 for Sentiment Analysis (https://www.kaggle.com/code/lucamassaron/fine-tune-llama-3-for-sentiment-analysis)\n",
    "- Finetune Llama 2 for Sentiment Analysis (https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 23 12:21:00 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# %pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "%pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "%pip install -q -U transformers==\"4.40.0\"\n",
    "%pip install -q -U accelerate\n",
    "%pip install -q -U datasets\n",
    "%pip install -q -U trl\n",
    "%pip install -q -U peft\n",
    "# %pip install -q -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'eng'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # Might not work on Kaggle\n",
    "model_name = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling two features in PyTorch related to memory efficiency and speed during operations on the Graphics Processing Unit (GPU) specifically for the scaled dot product attention (SDPA) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face token (https://huggingface.co/settings/tokens):\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "print(\"Hugging Face token (https://huggingface.co/settings/tokens):\")\n",
    "hf_token = input()\n",
    "!huggingface-cli login --token $hf_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF columns: ['Unnamed: 0', 'text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "\n",
      "Train DF size: 2214\n",
      "Validation DF size: 554\n",
      "Testing DF size: 116\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    'train': f'preprocessed_data/train/{lang}.csv', \n",
    "    'val': f'preprocessed_data/val/{lang}.csv',\n",
    "    'test': f'preprocessed_data/test/{lang}.csv',\n",
    "}\n",
    "dataset = load_dataset('alxxtexxr/SemEval2025-Task11-Dataset', data_files=data_files)\n",
    "\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "val_df = pd.DataFrame(dataset['val'])\n",
    "\n",
    "print(\"DF columns:\", list(train_df.columns))\n",
    "print()\n",
    "print(\"Train DF size:\", len(train_df))\n",
    "print(\"Validation DF size:\", len(val_df))\n",
    "print(\"Testing DF size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prompt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train prompts:\n",
      "\n",
      "Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
      "\n",
      "[I now have 12 of those canker sore suckers in my mouth along with a fever since friday.] = fear, sad\n",
      "================================================================================================================================================================================================\n",
      "Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
      "\n",
      "[It just... went away.] = fear, sad, surprise\n",
      "================================================================================================================================================================================================\n",
      "Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
      "\n",
      "[I naively walked up and stuck my head in the driver's window hole.] = fear, surprise\n",
      "================================================================================================================================================================================================\n",
      "\n",
      "Testing prompts:\n",
      "\n",
      "Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
      "\n",
      "[My mouth fell open `` No, no, no... I..] =\n",
      "================================================================================================================================================================================================\n",
      "Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
      "\n",
      "[You can barely make out your daughter's pale form in the darkness of your room.] =\n",
      "================================================================================================================================================================================================\n",
      "Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
      "\n",
      "[But after blinking my eyes for a few times lepas tu tampar-tampar muka sikit, memang sah la yang penghantar itu Hanis Zalikha.] =\n",
      "================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Analyze the emotion of the text within square brackets. Identify whether the emotion is one or a combination of the following: anger, fear, joy, sad, surprise, or neutral. \n",
    "\n",
    "[{text}] = {emotion}\"\"\"\n",
    "\n",
    "def create_prompt(row):\n",
    "    return prompt_template.format(text=row['text'], emotion=row['emotion']).strip()\n",
    "\n",
    "def create_test_prompt(row):\n",
    "    return prompt_template.format(text=row['text'], emotion=\"\").strip()\n",
    "\n",
    "train_df['prompt'] = train_df.apply(create_prompt, axis=1)\n",
    "val_df['prompt'] = val_df.apply(create_test_prompt, axis=1)\n",
    "test_df['prompt'] = test_df.apply(create_test_prompt, axis=1)\n",
    "\n",
    "print(\"Train prompts:\\n\")\n",
    "for prompt in train_df['prompt'].head(3):\n",
    "    print(prompt)\n",
    "    print(\"================================================================================================================================================================================================\")\n",
    "print()\n",
    "print(\"Testing prompts:\\n\")\n",
    "for prompt in test_df['prompt'].head(3):\n",
    "    print(prompt)\n",
    "    print(\"================================================================================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

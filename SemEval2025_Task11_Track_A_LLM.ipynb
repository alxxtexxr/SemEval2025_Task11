{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- Finetune Llama 3 for Sentiment Analysis (https://www.kaggle.com/code/lucamassaron/fine-tune-llama-3-for-sentiment-analysis)\n",
    "- Finetune Llama 2 for Sentiment Analysis (https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 24 03:38:27 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0             26W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "%pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "%pip install -q -U transformers\n",
    "%pip install -q -U accelerate\n",
    "%pip install -q -U datasets\n",
    "%pip install -q -U trl\n",
    "%pip install -q -U peft\n",
    "# %pip install -q -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = 'eng'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # Might not work on Kaggle\n",
    "model_id = 'meta-llama/Llama-3.2-1B-Instruct'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling two features in PyTorch related to memory efficiency and speed during operations on the Graphics Processing Unit (GPU) specifically for the scaled dot product attention (SDPA) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set random seed for Torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic algorithms\n",
    "\n",
    "    # Set random seed for Transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face token (https://huggingface.co/settings/tokens):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('/root/.cache/huggingface/token'):\n",
    "    print(\"Hugging Face token (https://huggingface.co/settings/tokens):\")\n",
    "    hf_token = input()\n",
    "    !huggingface-cli login --token $hf_token\n",
    "else:\n",
    "    print(\"Hugging Face token has already been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF columns: ['Unnamed: 0', 'text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "Emotions columns: ['anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "\n",
      "Train DF size: 2214\n",
      "Validation DF size: 554\n",
      "Testing DF size: 116\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    'train': f'preprocessed_data/train/{lang}.csv', \n",
    "    'val': f'preprocessed_data/val/{lang}.csv',\n",
    "    'test': f'preprocessed_data/test/{lang}.csv',\n",
    "}\n",
    "dataset = load_dataset('alxxtexxr/SemEval2025-Task11-Dataset', data_files=data_files)\n",
    "\n",
    "splits = data_files.keys()\n",
    "df = {split: pd.DataFrame(dataset[split]) for split in splits}\n",
    "\n",
    "cols = list(df['train'].columns)\n",
    "print(\"DF columns:\", cols)\n",
    "\n",
    "emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion']]\n",
    "# neutral_emotion = df['train'][df['train'][emotion_cols].sum(axis=1) == 0]['emotion'].iloc[0]\n",
    "# emotions = emotion_cols + [neutral_emotion]\n",
    "print(\"Emotions columns:\", emotion_cols)\n",
    "print()\n",
    "\n",
    "print(\"Train DF size:\", len(df['train']))\n",
    "print(\"Validation DF size:\", len(df['val']))\n",
    "print(\"Testing DF size:\", len(df['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prompt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train prompts:\n",
      "\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: I now have 12 of those canker sore suckers in my mouth along with a fever since friday.\n",
      "\n",
      "### Output\n",
      "Emotion(s): fear, sad\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: It just... went away.\n",
      "\n",
      "### Output\n",
      "Emotion(s): fear, sad, surprise\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: I naively walked up and stuck my head in the driver's window hole.\n",
      "\n",
      "### Output\n",
      "Emotion(s): fear, surprise\n",
      "================================================================================================================================================================================================\n",
      "\n",
      "Testing prompts:\n",
      "\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: My mouth fell open `` No, no, no... I..\n",
      "\n",
      "### Output\n",
      "Emotion(s):\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: You can barely make out your daughter's pale form in the darkness of your room.\n",
      "\n",
      "### Output\n",
      "Emotion(s):\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: But after blinking my eyes for a few times lepas tu tampar-tampar muka sikit, memang sah la yang penghantar itu Hanis Zalikha.\n",
      "\n",
      "### Output\n",
      "Emotion(s):\n",
      "================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "### Instruction\n",
    "Detect the emotion(s) in the given input text. \n",
    "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
    "\n",
    "### Input\n",
    "Text: {text}\n",
    "\n",
    "### Output\n",
    "Emotion(s): {emotion}\"\"\"\n",
    "\n",
    "def create_prompt(row):\n",
    "    emotion_list = row['emotion'].replace(\" \", \"\").split(\",\")\n",
    "    emotion = \", \".join([f\"{e}\" for e in row['emotion'].replace(\" \", \"\").split(\",\")])#[1:]#+ \"]\"\n",
    "    # emotion = '\\n'.join([f\"- {e}\" for e in emotion_list])[2:]\n",
    "    return prompt_template.format(text=row['text'], emotion=emotion).strip()\n",
    "\n",
    "def create_test_prompt(row):\n",
    "    return prompt_template.format(text=row['text'], emotion=\"\").strip()\n",
    "\n",
    "df['train']['prompt'] = df['train'].apply(create_prompt, axis=1)\n",
    "df['val']['prompt'] = df['val'].apply(create_test_prompt, axis=1)\n",
    "df['test']['prompt'] = df['test'].apply(create_test_prompt, axis=1)\n",
    "\n",
    "print(\"Train prompts:\\n\")\n",
    "for prompt in df['train']['prompt'].head(3):\n",
    "    print(prompt)\n",
    "    print(\"================================================================================================================================================================================================\")\n",
    "print()\n",
    "print(\"Testing prompts:\\n\")\n",
    "for prompt in df['test']['prompt'].head(3):\n",
    "    print(prompt)\n",
    "    print(\"================================================================================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max. prompt length: 673\n",
      "Validation max. prompt length: 586\n",
      "Testing max. prompt length: 527\n",
      "\n",
      "Max. prompt length: 673\n"
     ]
    }
   ],
   "source": [
    "max_seq_lengths = {split: df[split]['prompt'].str.len().max() for split in splits}\n",
    "max_seq_length = max(max_seq_lengths.values())\n",
    "\n",
    "print(\"Train max. prompt length:\", max_seq_lengths['train'])\n",
    "print(\"Validation max. prompt length:\", max_seq_lengths['val'])\n",
    "print(\"Testing max. prompt length:\", max_seq_lengths['test'])\n",
    "print()\n",
    "print(\"Max. prompt length:\", max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['prompt'],\n",
       "     num_rows: 2214\n",
       " }),\n",
       " 'val': Dataset({\n",
       "     features: ['prompt'],\n",
       "     num_rows: 554\n",
       " })}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {split: Dataset.from_pandas(df[split][['prompt']]) for split in ['train', 'val']}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7277c5e51ca4112b993f40f0780133f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5657e1b2b71746ac9c77429ea9951076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1827785d8145433a8e75a73ccc0b244e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0368b18608db4323b8f565a3422d45d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eab9b5b4b634d9cb3abded65d681524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2ea5240fe34efca52bff32291dbdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_dtype = torch.float16\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, max_seq_length=max_seq_length)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_new_tokens = df['train'].apply(lambda row: len(tokenizer.encode(row['emotion'])), axis=1).max()\n",
    "# print(\"Max. emotion tokens:\", max_new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation without Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Y (554):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = df['val'].apply(lambda row: row[emotion_cols].tolist(), axis=1).tolist()\n",
    "\n",
    "print(f\"True Y ({len(y_true)}):\")\n",
    "y_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y (554)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode_emotion(emotion, emotion_cols):\n",
    "    emotions = emotion.replace(\" \", \"\").split(\",\")\n",
    "    one_hot_emotion = [1 if emotion_col in emotions else 0 for emotion_col in emotion_cols]\n",
    "    return one_hot_emotion\n",
    "\n",
    "def predict(df_, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in range(len(df_)):\n",
    "        prompt = df_.iloc[i]['prompt']\n",
    "        pipe = pipeline(\n",
    "            task='text-generation',\n",
    "            model=model, \n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=32,\n",
    "            temperature=0.001,\n",
    "        )\n",
    "        result = pipe(prompt)\n",
    "        pred_emotion = result[0]['generated_text'].replace(prompt, \"\").split(\"\\n\")[0].lower()\n",
    "        pred_emotion_one_hot = one_hot_encode_emotion(pred_emotion, emotion_cols)\n",
    "        y_pred.append(pred_emotion_one_hot)\n",
    "        # if i == 5: break\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict(df['val'], model, tokenizer)\n",
    "print(f\"Predicted Y ({len(y_pred)})\")\n",
    "y_pred[:10]\n",
    "# 10m 32.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro-Average): 0.49547218628719275\n",
      "F1 Score (Macro-Average): 0.49731087609348473\n",
      "\n",
      "F1 Score for 'anger': 0.5555555555555555\n",
      "F1 Score for 'fear': 0.5239085239085239\n",
      "F1 Score for 'joy': 0.5384615384615384\n",
      "F1 Score for 'sad': 0.5886287625418061\n",
      "F1 Score for 'surprise': 0.28\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1 score for each type of averaging method\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0.0)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n",
    "# f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0.0)\n",
    "# f1_samples = f1_score(y_true, y_pred, average='samples', zero_division=0.0)\n",
    "f1_per_label = f1_score(y_true, y_pred, average=None, zero_division=0.0)\n",
    "\n",
    "print(f'F1 Score (Micro-Average): {f1_micro}')\n",
    "print(f'F1 Score (Macro-Average): {f1_macro}')\n",
    "# print(f'F1 Score (Weighted-Average): {f1_weighted}')\n",
    "# print(f'F1 Score (Samples-Average): {f1_samples}')\n",
    "print()\n",
    "\n",
    "# F1 score per label\n",
    "for label, f1 in zip(emotion_cols, f1_per_label):\n",
    "    print(f\"F1 Score for '{label}': {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

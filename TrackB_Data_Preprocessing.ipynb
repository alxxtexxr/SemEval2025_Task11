{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = 'eng'\n",
    "raw_data_dir = './data/public_data/'\n",
    "preprocessed_data_dir = './data/preprocessed_data/'\n",
    "repo_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "split_sizes = [0.7, 0.15, 0.15]\n",
    "assert sum(split_sizes) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length: 2768\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_train_track_b_00001</td>\n",
       "      <td>My Spanish language skills were fairly basic.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_train_track_b_00002</td>\n",
       "      <td>Don't mess with my orange juice.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_train_track_b_00003</td>\n",
       "      <td>So, I am from a science background and analyze...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_train_track_b_00004</td>\n",
       "      <td>I was writing away.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_train_track_b_00005</td>\n",
       "      <td>Apparently it wasn't as life threatening as I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>eng_train_track_b_02764</td>\n",
       "      <td>\"That's were those people went missing\".</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>eng_train_track_b_02765</td>\n",
       "      <td>`` Out of my mouth came, `` I didn't see Creep...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>eng_train_track_b_02766</td>\n",
       "      <td>My muscles all relax With the feeling of an em...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>eng_train_track_b_02767</td>\n",
       "      <td>I was going up to see my Avs play the Red Wings.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>eng_train_track_b_02768</td>\n",
       "      <td>By the time we landed in Paris ( and for the n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0     eng_train_track_b_00001   \n",
       "1     eng_train_track_b_00002   \n",
       "2     eng_train_track_b_00003   \n",
       "3     eng_train_track_b_00004   \n",
       "4     eng_train_track_b_00005   \n",
       "...                       ...   \n",
       "2763  eng_train_track_b_02764   \n",
       "2764  eng_train_track_b_02765   \n",
       "2765  eng_train_track_b_02766   \n",
       "2766  eng_train_track_b_02767   \n",
       "2767  eng_train_track_b_02768   \n",
       "\n",
       "                                                   text  Anger  Fear  Joy  \\\n",
       "0         My Spanish language skills were fairly basic.      0     1    0   \n",
       "1                      Don't mess with my orange juice.      2     0    0   \n",
       "2     So, I am from a science background and analyze...      0     0    0   \n",
       "3                                   I was writing away.      0     0    1   \n",
       "4     Apparently it wasn't as life threatening as I ...      0     1    0   \n",
       "...                                                 ...    ...   ...  ...   \n",
       "2763           \"That's were those people went missing\".      0     3    0   \n",
       "2764  `` Out of my mouth came, `` I didn't see Creep...      0     2    0   \n",
       "2765  My muscles all relax With the feeling of an em...      0     0    2   \n",
       "2766   I was going up to see my Avs play the Red Wings.      0     0    2   \n",
       "2767  By the time we landed in Paris ( and for the n...      0     0    0   \n",
       "\n",
       "      Sadness  Surprise  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           1         0  \n",
       "...       ...       ...  \n",
       "2763        1         2  \n",
       "2764        0         1  \n",
       "2765        0         0  \n",
       "2766        0         0  \n",
       "2767        0         0  \n",
       "\n",
       "[2768 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(raw_data_dir, f'train/track_b/{lang}.csv'))\n",
    "print(\"Training DF length:\", len(train_df))\n",
    "print()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_col_map = {\n",
    "    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n",
    "    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': 'überraschung' },\n",
    "    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "}\n",
    "emotion_cols = list(emotion_col_map[lang].values())\n",
    "\n",
    "empty_emotion_map = {\n",
    "    'eng': 'neutral',\n",
    "    'deu': 'neutral',\n",
    "    'sun': 'biasa',\n",
    "}\n",
    "\n",
    "# Rename emotion columns\n",
    "train_df = train_df.rename(columns=emotion_col_map[lang])\n",
    "\n",
    "# # Create 'emotion' column by combining the positive emotions\n",
    "# train_df['emotion'] = train_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "# train_df['emotion'] = train_df['emotion'].replace('', empty_emotion_map[lang]) # Fill empty emotion\n",
    "# # print(train_df['emotion'].value_counts())\n",
    "# # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot emotion columns: ['anger_0', 'anger_1', 'anger_2', 'anger_3', 'fear_0', 'fear_1', 'fear_2', 'fear_3', 'joy_0', 'joy_1', 'joy_2', 'joy_3', 'sad_0', 'sad_1', 'sad_2', 'sad_3', 'surprise_0', 'surprise_1', 'surprise_2', 'surprise_3']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "      <th>anger_0</th>\n",
       "      <th>anger_1</th>\n",
       "      <th>anger_2</th>\n",
       "      <th>...</th>\n",
       "      <th>joy_2</th>\n",
       "      <th>joy_3</th>\n",
       "      <th>sad_0</th>\n",
       "      <th>sad_1</th>\n",
       "      <th>sad_2</th>\n",
       "      <th>sad_3</th>\n",
       "      <th>surprise_0</th>\n",
       "      <th>surprise_1</th>\n",
       "      <th>surprise_2</th>\n",
       "      <th>surprise_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_train_track_b_00001</td>\n",
       "      <td>My Spanish language skills were fairly basic.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_train_track_b_00002</td>\n",
       "      <td>Don't mess with my orange juice.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_train_track_b_00003</td>\n",
       "      <td>So, I am from a science background and analyze...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_train_track_b_00004</td>\n",
       "      <td>I was writing away.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_train_track_b_00005</td>\n",
       "      <td>Apparently it wasn't as life threatening as I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0  eng_train_track_b_00001      My Spanish language skills were fairly basic.   \n",
       "1  eng_train_track_b_00002                   Don't mess with my orange juice.   \n",
       "2  eng_train_track_b_00003  So, I am from a science background and analyze...   \n",
       "3  eng_train_track_b_00004                                I was writing away.   \n",
       "4  eng_train_track_b_00005  Apparently it wasn't as life threatening as I ...   \n",
       "\n",
       "   anger  fear  joy  sad  surprise  anger_0  anger_1  anger_2  ...  joy_2  \\\n",
       "0      0     1    0    0         0        1        0        0  ...      0   \n",
       "1      2     0    0    0         0        0        0        1  ...      0   \n",
       "2      0     0    0    0         0        1        0        0  ...      0   \n",
       "3      0     0    1    0         0        1        0        0  ...      0   \n",
       "4      0     1    0    1         0        1        0        0  ...      0   \n",
       "\n",
       "   joy_3  sad_0  sad_1  sad_2  sad_3  surprise_0  surprise_1  surprise_2  \\\n",
       "0      0      1      0      0      0           1           0           0   \n",
       "1      0      1      0      0      0           1           0           0   \n",
       "2      0      1      0      0      0           1           0           0   \n",
       "3      0      1      0      0      0           1           0           0   \n",
       "4      0      0      1      0      0           1           0           0   \n",
       "\n",
       "   surprise_3  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the emotion\n",
    "one_hot_emotion_df = pd.get_dummies(train_df[emotion_cols], columns=emotion_cols, prefix=emotion_cols).astype(int)\n",
    "one_hot_emotion_cols = one_hot_emotion_df.columns.tolist()\n",
    "print(\"One-hot emotion columns:\", one_hot_emotion_cols)\n",
    "# print(one_hot_emotion_cols)\n",
    "train_df_one_hot = pd.concat([train_df, one_hot_emotion_df], axis=1)\n",
    "train_df_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length (splitted): 1937 --> ['text', 'anger_0', 'anger_1', 'anger_2', 'anger_3', 'fear_0', 'fear_1', 'fear_2', 'fear_3', 'joy_0', 'joy_1', 'joy_2', 'joy_3', 'sad_0', 'sad_1', 'sad_2', 'sad_3', 'surprise_0', 'surprise_1', 'surprise_2', 'surprise_3']\n",
      "Validation DF length: 415 --> ['text', 'anger_0', 'anger_1', 'anger_2', 'anger_3', 'fear_0', 'fear_1', 'fear_2', 'fear_3', 'joy_0', 'joy_1', 'joy_2', 'joy_3', 'sad_0', 'sad_1', 'sad_2', 'sad_3', 'surprise_0', 'surprise_1', 'surprise_2', 'surprise_3']\n",
      "Testing DF length: 416 --> ['text', 'anger_0', 'anger_1', 'anger_2', 'anger_3', 'fear_0', 'fear_1', 'fear_2', 'fear_3', 'joy_0', 'joy_1', 'joy_2', 'joy_3', 'sad_0', 'sad_1', 'sad_2', 'sad_3', 'surprise_0', 'surprise_1', 'surprise_2', 'surprise_3']\n"
     ]
    }
   ],
   "source": [
    "def create_stratify_col(df):\n",
    "    # Create 'stratify' column for stratified split\n",
    "    # train_df_one_hot['stratify'] = train_df_one_hot.apply(lambda row: ''.join(row[one_hot_emotion_cols].astype(str)), axis=1)\n",
    "    df['stratify'] = (df[emotion_cols] > 0).astype(int).apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
    "    # print(df['stratify'].value_counts())\n",
    "\n",
    "    # Identify classes with only one member\n",
    "    single_class = df['stratify'].value_counts()[df['stratify'].value_counts() == 1].index\n",
    "\n",
    "    # Assign a dummy value for the 'stratify' column for these classes\n",
    "    df.loc[df['stratify'].isin(single_class), 'stratify'] = 'dummy'\n",
    "\n",
    "create_stratify_col(train_df_one_hot)\n",
    "# print(train_df_one_hot['stratify'].value_counts())\n",
    "\n",
    "# Split training DF into training and validation DFs\n",
    "if len(split_sizes) == 3:\n",
    "    train_df_, val_test_df = train_test_split(train_df_one_hot[['text'] + emotion_cols + one_hot_emotion_cols],\n",
    "                                        train_size=split_sizes[0],\n",
    "                                        stratify=train_df_one_hot['stratify'],\n",
    "                                        random_state=seed)\n",
    "    train_df_ = train_df_[['text'] + one_hot_emotion_cols]\n",
    "    \n",
    "    create_stratify_col(val_test_df)\n",
    "    test_size = split_sizes[-1]/(split_sizes[1] + split_sizes[-1])\n",
    "    val_df, test_df = train_test_split(val_test_df[['text'] + one_hot_emotion_cols],\n",
    "                                        test_size=test_size,\n",
    "                                        stratify=val_test_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "    \n",
    "    print(\"Training DF length (splitted):\", len(train_df_), \"-->\", train_df_.columns.tolist())\n",
    "    print(\"Validation DF length:\", len(val_df), \"-->\", val_df.columns.tolist())\n",
    "    print(\"Testing DF length:\", len(test_df), \"-->\", test_df.columns.tolist())\n",
    "\n",
    "# dev_df = pd.read_csv(os.path.join(raw_data_dir, f'dev/track_a/{lang}_a.csv'))\n",
    "# dev_df = dev_df.rename(columns=emotion_col_map[lang])\n",
    "# dev_df['emotion'] = None\n",
    "# dev_df = dev_df[['text', 'emotion'] + emotion_cols]\n",
    "# print(\"Dev. DF length:\", len(dev_df), \"-->\", dev_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/preprocessed_data/track_b/eng_70_15_15\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "save_dir_name = lang + '_' + '_'.join([str(int(split_size * 100)) for split_size in split_sizes])\n",
    "save_dir = os.path.join(preprocessed_data_dir, 'track_b', save_dir_name)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df_.to_csv(os.path.join(save_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'), index=False)\n",
    "# dev_df.to_csv(os.path.join(save_dir, 'dev.csv'), index=False)\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset/commit/a63da5210ff95234be05ce46daabfd77ff824dde', commit_message='Upload folder using huggingface_hub', commit_description='', oid='a63da5210ff95234be05ce46daabfd77ff824dde', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data/track_b', save_dir_name),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

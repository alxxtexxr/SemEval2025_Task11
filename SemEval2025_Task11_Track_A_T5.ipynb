{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/alxxtexxr/SemEval_Task11/blob/main/SemEval2025_Task11_Track_A_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"nMvDJ4MM6hCm"},"source":["### References\n","\n","- Finetune T5 for classification and multiple choice (https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb)\n","\n","- Finetune T5 for sentiment span extraction (https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"0KAEHVX_xd2F"},"source":["# Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:56:30.310548Z","iopub.status.busy":"2024-10-21T10:56:30.309839Z","iopub.status.idle":"2024-10-21T10:56:44.542484Z","shell.execute_reply":"2024-10-21T10:56:44.541459Z","shell.execute_reply.started":"2024-10-21T10:56:30.310499Z"},"id":"JQpvD6_LfD5A","trusted":true},"outputs":[],"source":["!pip install -q pytorch_lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:56:44.544682Z","iopub.status.busy":"2024-10-21T10:56:44.544391Z","iopub.status.idle":"2024-10-21T10:56:56.604478Z","shell.execute_reply":"2024-10-21T10:56:56.603622Z","shell.execute_reply.started":"2024-10-21T10:56:44.544649Z"},"id":"3QtsN8HVIXu3","trusted":true},"outputs":[],"source":["import os\n","import random\n","import argparse\n","import logging\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import pytorch_lightning as pl\n","import textwrap\n","from pprint import pprint\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, get_linear_schedule_with_warmup\n","from sklearn.metrics import f1_score, confusion_matrix\n","from tqdm.auto import tqdm"]},{"cell_type":"markdown","metadata":{"id":"B0V_2IghxhZ3"},"source":["# Config"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T11:05:49.251694Z","iopub.status.busy":"2024-10-21T11:05:49.251280Z","iopub.status.idle":"2024-10-21T11:05:49.260267Z","shell.execute_reply":"2024-10-21T11:05:49.259327Z","shell.execute_reply.started":"2024-10-21T11:05:49.251657Z"},"id":"3nbqL5QyesUA","outputId":"16a0c102-aad7-4bd8-903c-785906506451","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'seed': 42,\n"," 'lang': 'eng',\n"," 'data_dir': '/kaggle/working/public_data/',\n"," 'preprocessed_data_dir': '/kaggle/working/preprocessed_data/',\n"," 'output_dir': '/kaggle/working/t5-emotion-detection-eng/',\n"," 'model_name_or_path': 'google-t5/t5-large',\n"," 'tokenizer_name_or_path': 'google-t5/t5-large',\n"," 'max_seq_length': 512,\n"," 'learning_rate': 0.0003,\n"," 'weight_decay': 0.0,\n"," 'adam_epsilon': 1e-08,\n"," 'warmup_steps': 0,\n"," 'train_batch_size': 8,\n"," 'eval_batch_size': 8,\n"," 'num_train_epochs': 2,\n"," 'gradient_accumulation_steps': 16,\n"," 'early_stop_callback': False,\n"," 'fp_16': True,\n"," 'opt_level': 'O1',\n"," 'max_grad_norm': 1.0}\n"]}],"source":["args_dict = dict(\n","    seed = 42,\n","    lang = 'eng', # 'eng' | 'deu' | 'ptbr' | 'rus' | 'sun'\n","\n","    # Directories for Colab\n","    # data_dir = '/content/drive/Shareddrives/Projects/SemEval2025_Task11/public_data/',\n","    # preprocessed_data_dir = '/content/drive/Shareddrives/Projects/SemEval2025_Task11/preprocessed_data/',\n","    # output_dir = '/content/drive/Shareddrives/Projects/SemEval2025_Task11/outputs/t5-emotion-detection-eng/',\n","\n","    # Directories for Kaggle\n","    data_dir = '/kaggle/working/public_data/',\n","    preprocessed_data_dir = '/kaggle/working/preprocessed_data/',\n","    output_dir = '/kaggle/working/t5-emotion-detection-eng/',\n","    \n","    # Model for English\n","    model_name_or_path = 'google-t5/t5-large',\n","    tokenizer_name_or_path = 'google-t5/t5-large',\n","\n","    # Model for Non-English\n","    # model_name_or_path = 'google/mt5-small',\n","    # tokenizer_name_or_path = 'google/mt5-small',\n","\n","    # Model for Indonesian/Sundanese\n","    # model_name_or_path = 'indonlp/cendol-mt5-small-inst',\n","    # tokenizer_name_or_path = 'indonlp/cendol-mt5-small-inst',\n","\n","    max_seq_length = 512,\n","    learning_rate = 3e-4,\n","    weight_decay = 0.0,\n","    adam_epsilon = 1e-8,\n","    warmup_steps = 0,\n","    train_batch_size = 8,\n","    eval_batch_size = 8,\n","    num_train_epochs = 2,\n","    gradient_accumulation_steps = 16,\n","    # n_gpu = -1, # use all available GPUs\n","    early_stop_callback = False,\n","    fp_16 = True, # if you want to enable 16-bit training then install apex and set this to true\n","    opt_level = 'O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n","    max_grad_norm = 1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",")\n","args = argparse.Namespace(**args_dict)\n","pprint(args_dict, sort_dicts=False)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:57:50.687309Z","iopub.status.busy":"2024-10-21T10:57:50.686633Z","iopub.status.idle":"2024-10-21T10:57:50.743138Z","shell.execute_reply":"2024-10-21T10:57:50.742389Z","shell.execute_reply.started":"2024-10-21T10:57:50.687264Z"},"id":"1x_CHBifXIBW","trusted":true},"outputs":[],"source":["# Set random seed\n","def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(args.seed)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:43:13.020469Z","iopub.status.busy":"2024-10-21T10:43:13.020127Z","iopub.status.idle":"2024-10-21T10:43:13.026692Z","shell.execute_reply":"2024-10-21T10:43:13.025715Z","shell.execute_reply.started":"2024-10-21T10:43:13.020417Z"},"id":"lym9dn7RxLfk","outputId":"915b51a0-dbf0-4288-da59-8dbb1d8d9000","trusted":true},"outputs":[],"source":["# Load the Drive helper and mount\n","# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"1c7dn-x-efRx"},"source":["# Data"]},{"cell_type":"markdown","metadata":{"id":"XCjKfs3YHzvo"},"source":["## Upload Data"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:43:13.028250Z","iopub.status.busy":"2024-10-21T10:43:13.027940Z","iopub.status.idle":"2024-10-21T10:43:13.035654Z","shell.execute_reply":"2024-10-21T10:43:13.034706Z","shell.execute_reply.started":"2024-10-21T10:43:13.028220Z"},"id":"O0nEdEJFHRJd","trusted":true},"outputs":[],"source":["# # Upload public_data.zip\n","# from google.colab import files\n","# uploaded_files = files.upload()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:43:13.037204Z","iopub.status.busy":"2024-10-21T10:43:13.036833Z","iopub.status.idle":"2024-10-21T10:43:13.043369Z","shell.execute_reply":"2024-10-21T10:43:13.042463Z","shell.execute_reply.started":"2024-10-21T10:43:13.037156Z"},"id":"Y9zhyA-WHy3j","trusted":true},"outputs":[],"source":["# !unzip public_data.zip"]},{"cell_type":"markdown","metadata":{},"source":["## Download Data from Drive"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:57:55.456560Z","iopub.status.busy":"2024-10-21T10:57:55.456143Z","iopub.status.idle":"2024-10-21T10:58:07.164349Z","shell.execute_reply":"2024-10-21T10:58:07.162962Z","shell.execute_reply.started":"2024-10-21T10:57:55.456521Z"},"trusted":true},"outputs":[],"source":["!pip install -q gdown"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:07.989957Z","iopub.status.busy":"2024-10-21T10:58:07.989541Z","iopub.status.idle":"2024-10-21T10:58:14.905763Z","shell.execute_reply":"2024-10-21T10:58:14.904748Z","shell.execute_reply.started":"2024-10-21T10:58:07.989918Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1RbjQCsuA6pnuSMBAWC85kNUYBRrzen1r\n","To: /kaggle/working/public_data.zip\n","100%|███████████████████████████████████████| 3.35M/3.35M [00:00<00:00, 225MB/s]\n"]}],"source":["!gdown https://drive.google.com/uc?id=1RbjQCsuA6pnuSMBAWC85kNUYBRrzen1r"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:14.907846Z","iopub.status.busy":"2024-10-21T10:58:14.907514Z","iopub.status.idle":"2024-10-21T10:58:16.000748Z","shell.execute_reply":"2024-10-21T10:58:15.999811Z","shell.execute_reply.started":"2024-10-21T10:58:14.907810Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  public_data.zip\n","   creating: public_data/\n","   creating: public_data/train/\n","   creating: public_data/dev/\n","   creating: public_data/train/track_b/\n","   creating: public_data/train/track_a/\n","   creating: public_data/dev/track_b/\n","   creating: public_data/dev/track_c/\n","   creating: public_data/dev/track_a/\n","  inflating: public_data/train/track_b/ptbr.csv  \n","  inflating: public_data/train/track_b/rus.csv  \n","  inflating: public_data/train/track_b/amh.csv  \n","  inflating: public_data/train/track_b/deu.csv  \n","  inflating: public_data/train/track_b/eng.csv  \n","  inflating: public_data/train/track_a/sun.csv  \n","  inflating: public_data/train/track_a/oro.csv  \n","  inflating: public_data/train/track_a/tir.csv  \n","  inflating: public_data/train/track_a/afr.csv  \n","  inflating: public_data/train/track_a/ptbr.csv  \n","  inflating: public_data/train/track_a/rus.csv  \n","  inflating: public_data/train/track_a/amh.csv  \n","  inflating: public_data/train/track_a/deu.csv  \n","  inflating: public_data/train/track_a/eng.csv  \n","  inflating: public_data/train/track_a/som.csv  \n","  inflating: public_data/dev/track_b/amh_b.csv  \n","  inflating: public_data/dev/track_b/eng_b.csv  \n","  inflating: public_data/dev/track_b/deu_b.csv  \n","  inflating: public_data/dev/track_b/rus_b.csv  \n","  inflating: public_data/dev/track_b/ptbr_b.csv  \n","  inflating: public_data/dev/track_c/ind_c.csv  \n","  inflating: public_data/dev/track_c/oro_c.csv  \n","  inflating: public_data/dev/track_c/tir_c.csv  \n","  inflating: public_data/dev/track_c/jav_c.csv  \n","  inflating: public_data/dev/track_c/amh_c.csv  \n","  inflating: public_data/dev/track_c/eng_c.csv  \n","  inflating: public_data/dev/track_c/som_c.csv  \n","  inflating: public_data/dev/track_c/sun_c.csv  \n","  inflating: public_data/dev/track_c/deu_c.csv  \n","  inflating: public_data/dev/track_c/rus_c.csv  \n","  inflating: public_data/dev/track_c/afr_c.csv  \n","  inflating: public_data/dev/track_c/ptbr_c.csv  \n","  inflating: public_data/dev/track_a/tir_a.csv  \n","  inflating: public_data/dev/track_a/oro_a.csv  \n","  inflating: public_data/dev/track_a/amh_a.csv  \n","  inflating: public_data/dev/track_a/som_a.csv  \n","  inflating: public_data/dev/track_a/eng_a.csv  \n","  inflating: public_data/dev/track_a/rus_a.csv  \n","  inflating: public_data/dev/track_a/deu_a.csv  \n","  inflating: public_data/dev/track_a/sun_a.csv  \n","  inflating: public_data/dev/track_a/ptbr_a.csv  \n","  inflating: public_data/dev/track_a/afr_a.csv  \n"]}],"source":["!unzip public_data.zip"]},{"cell_type":"markdown","metadata":{"id":"xgb_s9tCo0kf"},"source":["## Preprocess Data"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"execution":{"iopub.execute_input":"2024-10-21T10:58:20.574997Z","iopub.status.busy":"2024-10-21T10:58:20.574597Z","iopub.status.idle":"2024-10-21T10:58:20.627244Z","shell.execute_reply":"2024-10-21T10:58:20.626345Z","shell.execute_reply.started":"2024-10-21T10:58:20.574958Z"},"id":"clAhx3D8Ion5","outputId":"3b96b7c0-9e33-440f-d41d-23c17b5a8615","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training DF length: 2768\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>Anger</th>\n","      <th>Fear</th>\n","      <th>Joy</th>\n","      <th>Sadness</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>eng_train_track_a_00001</td>\n","      <td>But not very happy.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>eng_train_track_a_00002</td>\n","      <td>Well she's not gon na last the whole song like...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eng_train_track_a_00003</td>\n","      <td>She sat at her Papa's recliner sofa only to mo...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eng_train_track_a_00004</td>\n","      <td>Yes, the Oklahoma city bombing.</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>eng_train_track_a_00005</td>\n","      <td>They were dancing to Bolero.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2763</th>\n","      <td>eng_train_track_a_02764</td>\n","      <td>\"Yeah, but did you just find that?</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2764</th>\n","      <td>eng_train_track_a_02765</td>\n","      <td>I did as little as possible with my right hand...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2765</th>\n","      <td>eng_train_track_a_02766</td>\n","      <td>Okay that sucks, right?</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2766</th>\n","      <td>eng_train_track_a_02767</td>\n","      <td>The spark leaped through his body into mine, a...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2767</th>\n","      <td>eng_train_track_a_02768</td>\n","      <td>He had 4 inches and 40 pounds on me and I stil...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2768 rows × 7 columns</p>\n","</div>"],"text/plain":["                           id  \\\n","0     eng_train_track_a_00001   \n","1     eng_train_track_a_00002   \n","2     eng_train_track_a_00003   \n","3     eng_train_track_a_00004   \n","4     eng_train_track_a_00005   \n","...                       ...   \n","2763  eng_train_track_a_02764   \n","2764  eng_train_track_a_02765   \n","2765  eng_train_track_a_02766   \n","2766  eng_train_track_a_02767   \n","2767  eng_train_track_a_02768   \n","\n","                                                   text  Anger  Fear  Joy  \\\n","0                                   But not very happy.      0     0    1   \n","1     Well she's not gon na last the whole song like...      0     0    1   \n","2     She sat at her Papa's recliner sofa only to mo...      0     0    0   \n","3                       Yes, the Oklahoma city bombing.      1     1    0   \n","4                          They were dancing to Bolero.      0     0    1   \n","...                                                 ...    ...   ...  ...   \n","2763                 \"Yeah, but did you just find that?      0     1    0   \n","2764  I did as little as possible with my right hand...      0     0    0   \n","2765                            Okay that sucks, right?      1     0    0   \n","2766  The spark leaped through his body into mine, a...      0     1    0   \n","2767  He had 4 inches and 40 pounds on me and I stil...      0     0    1   \n","\n","      Sadness  Surprise  \n","0           1         0  \n","1           0         0  \n","2           0         0  \n","3           1         1  \n","4           0         0  \n","...       ...       ...  \n","2763        0         1  \n","2764        0         0  \n","2765        1         0  \n","2766        0         1  \n","2767        0         1  \n","\n","[2768 rows x 7 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.read_csv(os.path.join(args.data_dir, f'train/track_a/{args.lang}.csv'))\n","print(\"Training DF length:\", len(train_df))\n","print()\n","train_df"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:58:23.445234Z","iopub.status.busy":"2024-10-21T10:58:23.444286Z","iopub.status.idle":"2024-10-21T10:58:23.578151Z","shell.execute_reply":"2024-10-21T10:58:23.577210Z","shell.execute_reply.started":"2024-10-21T10:58:23.445163Z"},"id":"9Y1trfuWozkE","outputId":"0d49f21e-3b3c-468d-b05a-f1cab253f916","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["emotion\n","joy                                429\n","fear, sad                          412\n","fear                               411\n","fear, surprise                     324\n","neutral                            239\n","sad                                133\n","fear, sad, surprise                124\n","surprise                           114\n","joy, surprise                      108\n","anger, fear, sad                    77\n","anger, fear                         66\n","anger                               54\n","anger, fear, sad, surprise          51\n","fear, joy                           49\n","anger, fear, surprise               42\n","fear, joy, surprise                 37\n","joy, sad                            25\n","anger, sad                          20\n","anger, surprise                     13\n","sad, surprise                       11\n","fear, joy, sad                      10\n","fear, joy, sad, surprise             5\n","joy, sad, surprise                   4\n","anger, sad, surprise                 3\n","anger, joy                           3\n","anger, fear, joy, sad, surprise      2\n","anger, joy, surprise                 1\n","anger, fear, joy, sad                1\n","Name: count, dtype: int64\n","\n","Training DF length (splitted): 2214\n","Validation DF length: 554\n","Testing DF length: 116\n"]}],"source":["emotion_col_map = {\n","    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n","    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': 'überraschung' },\n","    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n","}\n","emotion_cols = list(emotion_col_map[args.lang].values())\n","\n","empty_emotion_map = {\n","    'eng': 'neutral',\n","    'deu': 'neutral',\n","    'sun': 'biasa',\n","}\n","\n","# Rename emotion columns\n","train_df = train_df.rename(columns=emotion_col_map[args.lang])\n","\n","# Create 'emotion' column by combining the positive emotions\n","train_df['emotion'] = train_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n","train_df['emotion'] = train_df['emotion'].replace('', empty_emotion_map[args.lang]) # Fill empty emotion\n","print(train_df['emotion'].value_counts())\n","print()\n","\n","# Create 'stratify' column for stratified split\n","train_df['stratify'] = train_df['emotion']\n","\n","# Identify classes with only one member\n","single_class = train_df['emotion'].value_counts()[train_df['emotion'].value_counts() == 1].index\n","\n","# Assign a dummy value for the 'stratify' column for these classes\n","train_df.loc[train_df['emotion'].isin(single_class), 'stratify'] = 'dummy'\n","\n","# Split training DF into training and validation DFs\n","train_df_, val_df = train_test_split(train_df[['text', 'emotion'] + emotion_cols],\n","                                     test_size=0.2,\n","                                     stratify=train_df['stratify'],\n","                                     random_state=args.seed)\n","print(\"Training DF length (splitted):\", len(train_df_))\n","print(\"Validation DF length:\", len(val_df))\n","\n","test_df = pd.read_csv(os.path.join(args.data_dir, f'dev/track_a/{args.lang}_a.csv'))\n","test_df['emotion'] = None\n","test_df = test_df[['text', 'emotion']]\n","print(\"Testing DF length:\", len(test_df))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:26.390624Z","iopub.status.busy":"2024-10-21T10:58:26.390248Z","iopub.status.idle":"2024-10-21T10:58:29.457755Z","shell.execute_reply":"2024-10-21T10:58:29.456743Z","shell.execute_reply.started":"2024-10-21T10:58:26.390590Z"},"id":"aVSy1cnKqGiV","trusted":true},"outputs":[],"source":["# Save preprocessed data\n","train_dir = os.path.join(args.preprocessed_data_dir, 'train')\n","val_dir = os.path.join(args.preprocessed_data_dir, 'val')\n","test_dir = os.path.join(args.preprocessed_data_dir, 'test')\n","\n","!mkdir -p $train_dir\n","!mkdir -p $val_dir\n","!mkdir -p $test_dir\n","\n","train_df_.to_csv(os.path.join(train_dir, f'{args.lang}.csv'))\n","val_df.to_csv(os.path.join(val_dir, f'{args.lang}.csv'))\n","test_df.to_csv(os.path.join(test_dir, f'{args.lang}.csv'))"]},{"cell_type":"markdown","metadata":{"id":"JW31ZSJrKozM"},"source":["## Create Dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:58:29.593149Z","iopub.status.busy":"2024-10-21T10:58:29.592794Z","iopub.status.idle":"2024-10-21T10:58:30.519347Z","shell.execute_reply":"2024-10-21T10:58:30.518120Z","shell.execute_reply.started":"2024-10-21T10:58:29.593110Z"},"id":"OMtwkxbELcat","outputId":"99a6a119-393b-44ab-8e18-5bebe5ab9132","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"554ef054c0954838b1ed1528605e24df","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5d66d6d69654456997271c2004783d9","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"815ca2e4bc714693bc285448583ba284","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, clean_up_tokenization_spaces=False)\n","# model = AutoModelForSeq2SeqLM.from_pretrained(args.tokenizer_name_or_path)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:58:32.162708Z","iopub.status.busy":"2024-10-21T10:58:32.161987Z","iopub.status.idle":"2024-10-21T10:58:32.179217Z","shell.execute_reply":"2024-10-21T10:58:32.178246Z","shell.execute_reply.started":"2024-10-21T10:58:32.162666Z"},"id":"rNaO9xYPUKLX","outputId":"453162eb-3dd6-4df7-a933-00fce52f1105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Emotion token lengths:\n","{'anger': 2,\n"," 'anger, fear': 4,\n"," 'anger, fear, joy, sad': 8,\n"," 'anger, fear, joy, sad, surprise': 10,\n"," 'anger, fear, sad': 6,\n"," 'anger, fear, sad, surprise': 8,\n"," 'anger, fear, surprise': 6,\n"," 'anger, joy': 4,\n"," 'anger, joy, surprise': 6,\n"," 'anger, sad': 4,\n"," 'anger, sad, surprise': 6,\n"," 'anger, surprise': 4,\n"," 'fear': 2,\n"," 'fear, joy': 4,\n"," 'fear, joy, sad': 6,\n"," 'fear, joy, sad, surprise': 8,\n"," 'fear, joy, surprise': 6,\n"," 'fear, sad': 4,\n"," 'fear, sad, surprise': 6,\n"," 'fear, surprise': 4,\n"," 'joy': 2,\n"," 'joy, sad': 4,\n"," 'joy, sad, surprise': 6,\n"," 'joy, surprise': 4,\n"," 'neutral': 2,\n"," 'sad': 2,\n"," 'sad, surprise': 4,\n"," 'surprise': 2}\n","\n","Target max. length: 10\n"]}],"source":["emotion_token_lengths = {emotion: len(tokenizer.encode(emotion)) for emotion in train_df['emotion'].unique()}\n","print(\"Emotion token lengths:\")\n","pprint(emotion_token_lengths, width=1)\n","print()\n","\n","target_max_len = max(emotion_token_lengths.values())\n","print(\"Target max. length:\", target_max_len)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:40.490717Z","iopub.status.busy":"2024-10-21T10:58:40.489812Z","iopub.status.idle":"2024-10-21T10:58:40.504611Z","shell.execute_reply":"2024-10-21T10:58:40.503228Z","shell.execute_reply.started":"2024-10-21T10:58:40.490671Z"},"id":"YqGSnRvhK2zR","trusted":true},"outputs":[],"source":["class EmotionDataset(Dataset):\n","  def __init__(self, tokenizer,\n","               lang, one_hot_class_columns,\n","               data_dir, data_split,\n","               data_column='text', class_column='emotion', max_len=512):\n","    self.data_column = data_column\n","    self.one_hot_class_columns = one_hot_class_columns\n","    self.class_column = class_column\n","\n","    self.data = pd.read_csv(os.path.join(data_dir, data_split, f'{lang}.csv'))\n","\n","    self.max_len = max_len\n","    self.tokenizer = tokenizer\n","    self.inputs = []\n","    self.targets = []\n","    self.one_hot_targets = []\n","\n","    self._build()\n","\n","  def __len__(self):\n","    return len(self.inputs)\n","\n","  def __getitem__(self, index):\n","    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n","    target_ids = self.targets[index][\"input_ids\"].squeeze()\n","\n","    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","\n","    return {\n","        \"source_ids\": source_ids,\n","        \"source_mask\": src_mask,\n","        \"target_ids\": target_ids,\n","        \"target_mask\": target_mask,\n","        \"one_hot_target\": self.one_hot_targets[index],\n","    }\n","\n","  def _build(self):\n","    for idx in range(len(self.data)):\n","      input_, target, one_hot_target = self.data.loc[idx, self.data_column], self.data.loc[idx, self.class_column], self.data.loc[idx, self.one_hot_class_columns]\n","      one_hot_target = one_hot_target.values.tolist()\n","\n","      # input_ = input_ + ' </s>'\n","      # target = target + \" </s>\"\n","\n","      # tokenize inputs\n","      tokenized_inputs = self.tokenizer.batch_encode_plus(\n","          [input_], max_length=self.max_len, return_tensors=\"pt\", padding='max_length', truncation=True,\n","      )\n","\n","      # tokenize targets\n","      tokenized_targets = self.tokenizer.batch_encode_plus(\n","          [target], max_length=target_max_len, return_tensors=\"pt\", padding='max_length', truncation=True,\n","      )\n","\n","      self.inputs.append(tokenized_inputs)\n","      self.targets.append(tokenized_targets)\n","      self.one_hot_targets.append(one_hot_target)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:43.351431Z","iopub.status.busy":"2024-10-21T10:58:43.351023Z","iopub.status.idle":"2024-10-21T10:58:43.359006Z","shell.execute_reply":"2024-10-21T10:58:43.358045Z","shell.execute_reply.started":"2024-10-21T10:58:43.351391Z"},"id":"GZ8sUdcHfkn3","trusted":true},"outputs":[],"source":["def get_dataset(tokenizer, type_path, args):\n","    return EmotionDataset(tokenizer=tokenizer, lang=args.lang, one_hot_class_columns=emotion_cols,\n","                          data_dir=args.preprocessed_data_dir, data_split=type_path, max_len=args.max_seq_length)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:58:45.110563Z","iopub.status.busy":"2024-10-21T10:58:45.109828Z","iopub.status.idle":"2024-10-21T10:58:48.031440Z","shell.execute_reply":"2024-10-21T10:58:48.030404Z","shell.execute_reply.started":"2024-10-21T10:58:45.110510Z"},"id":"f-q69dlzLXFk","outputId":"0259e037-5d81-4cdd-e526-2afd26486082","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["I now have 12 of those canker sore suckers in my mouth along with a fever since friday.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","fear, sad</s><pad><pad><pad><pad><pad><pad>\n","[0, 1, 0, 1, 0]\n","\n","It just... went away.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","fear, sad, surprise</s><pad><pad><pad><pad>\n","[0, 1, 0, 1, 1]\n","\n","I naively walked up and stuck my head in the driver's window hole.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","fear, surprise</s><pad><pad><pad><pad><pad><pad>\n","[0, 1, 0, 0, 1]\n","\n"]}],"source":["train_set = get_dataset(tokenizer, 'train', args)\n","\n","for i in range(3):\n","    d = train_set[i]\n","    print(tokenizer.decode(d['source_ids']))\n","    print(tokenizer.decode(d['target_ids']))\n","    print(d['one_hot_target'])\n","    print()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:58:50.670959Z","iopub.status.busy":"2024-10-21T10:58:50.670555Z","iopub.status.idle":"2024-10-21T10:58:50.677863Z","shell.execute_reply":"2024-10-21T10:58:50.676936Z","shell.execute_reply.started":"2024-10-21T10:58:50.670921Z"},"id":"YTucjKinOA7q","outputId":"393407ce-81ae-4b87-aa3a-db8680c96a3e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0, 1, 0, 1, 0], [0, 1, 0, 1, 1]]\n"]}],"source":["train_loader = DataLoader(train_set, batch_size=2)\n","batch = next(iter(train_loader))\n","print(torch.stack(batch['one_hot_target']).T.tolist())"]},{"cell_type":"markdown","metadata":{"id":"v_XYyxaZeb2V"},"source":["# Training"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:52.989322Z","iopub.status.busy":"2024-10-21T10:58:52.988513Z","iopub.status.idle":"2024-10-21T10:58:53.012290Z","shell.execute_reply":"2024-10-21T10:58:53.011210Z","shell.execute_reply.started":"2024-10-21T10:58:52.989282Z"},"id":"wdEAB-aif4Zu","trusted":true},"outputs":[],"source":["class T5FineTuner(pl.LightningModule):\n","  def __init__(self, hparams):\n","    super(T5FineTuner, self).__init__()\n","    self.automatic_optimization = False\n","\n","    # self.hparams = hparams\n","    self.save_hyperparameters(hparams)\n","\n","    self.model = AutoModelForSeq2SeqLM.from_pretrained(hparams.model_name_or_path)\n","    self.tokenizer = AutoTokenizer.from_pretrained(hparams.tokenizer_name_or_path, clean_up_tokenization_spaces=False)\n","\n","    self.training_step_outputs = []\n","    self.validation_step_outputs = []\n","\n","  def is_logger(self):\n","    # return self.trainer.proc_rank <= 0\n","    return self.trainer.global_rank <= 0\n","\n","  def forward(\n","      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n","  ):\n","    return self.model(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        decoder_input_ids=decoder_input_ids,\n","        decoder_attention_mask=decoder_attention_mask,\n","        labels=labels,\n","    )\n","\n","  def _step(self, batch):\n","    labels = batch[\"target_ids\"]\n","    labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","    outputs = self(\n","        input_ids=batch[\"source_ids\"],\n","        attention_mask=batch[\"source_mask\"],\n","        labels=labels,\n","        decoder_attention_mask=batch['target_mask']\n","    )\n","\n","    loss = outputs[0]\n","    return loss\n","\n","  def training_step(self, batch, batch_idx):\n","    opt = self.optimizers()\n","\n","    # scale losses by 1/N (for N batches of gradient accumulation)\n","    N = self.hparams.gradient_accumulation_steps\n","    loss = self._step(batch) / N\n","    self.manual_backward(loss)\n","\n","    # accumulate gradients of N batches\n","    if (batch_idx + 1) % N == 0:\n","        # clip gradients\n","        self.clip_gradients(opt, gradient_clip_val=self.hparams.max_grad_norm, gradient_clip_algorithm=\"norm\")\n","\n","        opt.step()\n","        opt.zero_grad()\n","        \n","        self.lr_scheduler.step()\n","\n","    tensorboard_logs = {\"train_loss\": loss}\n","    self.training_step_outputs.append({\"loss\": loss})\n","    return {\"loss\": loss, \"log\": tensorboard_logs}\n","\n","  # def training_epoch_end(self, outputs):\n","  def on_train_epoch_end(self):\n","    avg_train_loss = torch.stack([x[\"loss\"] for x in self.training_step_outputs]).mean()\n","    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n","    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n","\n","  def validation_step(self, batch, batch_idx):\n","    loss = self._step(batch)\n","    self.validation_step_outputs.append({\"val_loss\": loss})\n","    return {\"val_loss\": loss}\n","\n","  # def validation_epoch_end(self, outputs):\n","  def on_validation_epoch_end(self):\n","    avg_loss = torch.stack([x[\"val_loss\"] for x in self.validation_step_outputs]).mean()\n","    tensorboard_logs = {\"val_loss\": avg_loss}\n","    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n","\n","  def configure_optimizers(self):\n","    \"Prepare optimizer and schedule (linear warmup and decay)\"\n","\n","    model = self.model\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": self.hparams.weight_decay,\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n","    self.opt = optimizer\n","    return [optimizer]\n","\n","#   def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n","#     # if self.trainer.use_tpu:\n","#     #   xm.optimizer_step(optimizer)\n","#     # else:\n","#     #   optimizer.step()\n","#     optimizer.step()\n","#     optimizer.zero_grad()\n","#     self.lr_scheduler.step()\n","\n","  def get_tqdm_dict(self):\n","    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n","    return tqdm_dict\n","\n","  def train_dataloader(self):\n","    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n","    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size,\n","                            drop_last=True, shuffle=True, num_workers=2)\n","    t_total = (\n","        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n","        // self.hparams.gradient_accumulation_steps\n","        * float(self.hparams.num_train_epochs)\n","    )\n","    scheduler = get_linear_schedule_with_warmup(\n","        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n","    )\n","    self.lr_scheduler = scheduler\n","    return dataloader\n","\n","  def val_dataloader(self):\n","    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n","    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=2)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:56.796913Z","iopub.status.busy":"2024-10-21T10:58:56.796266Z","iopub.status.idle":"2024-10-21T10:58:56.805868Z","shell.execute_reply":"2024-10-21T10:58:56.804823Z","shell.execute_reply.started":"2024-10-21T10:58:56.796875Z"},"id":"c8KSuiwRfTx7","trusted":true},"outputs":[],"source":["logger = logging.getLogger(__name__)\n","\n","class LoggingCallback(pl.Callback):\n","  def on_validation_end(self, trainer, pl_module):\n","    logger.info(\"***** Validation results *****\")\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","      # Log results\n","      for key in sorted(metrics):\n","        if key not in [\"log\", \"progress_bar\"]:\n","          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","\n","  def on_test_end(self, trainer, pl_module):\n","    logger.info(\"***** Test results *****\")\n","\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","\n","      # Log and save results to file\n","      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n","      with open(output_test_results_file, \"w\") as writer:\n","        for key in sorted(metrics):\n","          if key not in [\"log\", \"progress_bar\"]:\n","            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T10:58:59.325125Z","iopub.status.busy":"2024-10-21T10:58:59.324237Z","iopub.status.idle":"2024-10-21T10:59:00.325379Z","shell.execute_reply":"2024-10-21T10:59:00.324400Z","shell.execute_reply.started":"2024-10-21T10:58:59.325084Z"},"id":"NqxntAOgekzx","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["!mkdir -p $args.output_dir"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T11:05:21.521818Z","iopub.status.busy":"2024-10-21T11:05:21.521040Z","iopub.status.idle":"2024-10-21T11:05:21.527305Z","shell.execute_reply":"2024-10-21T11:05:21.526369Z","shell.execute_reply.started":"2024-10-21T11:05:21.521769Z"},"id":"iw-RjBvJe_CP","trusted":true},"outputs":[],"source":["checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    # filepath=args.output_dir,\n","    # prefix=\"checkpoint\",\n","    monitor = \"val_loss\",\n","    mode = \"min\",\n","    save_top_k = 5\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T10:59:04.876904Z","iopub.status.busy":"2024-10-21T10:59:04.876492Z","iopub.status.idle":"2024-10-21T10:59:18.885149Z","shell.execute_reply":"2024-10-21T10:59:18.884343Z","shell.execute_reply.started":"2024-10-21T10:59:04.876865Z"},"id":"RBKDZjxMfp1p","outputId":"48deb233-4f4c-4ca9-b13d-0ad4d4406ecb","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfd0c1db17c14266bab5e0adf3ea1ee9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef14f0b63d3249c7a5847aed2d677209","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model = T5FineTuner(args)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-21T11:06:21.020145Z","iopub.status.busy":"2024-10-21T11:06:21.019761Z","iopub.status.idle":"2024-10-21T11:06:21.074255Z","shell.execute_reply":"2024-10-21T11:06:21.073333Z","shell.execute_reply.started":"2024-10-21T11:06:21.020109Z"},"id":"kHIKfQEzvNrb","outputId":"fb4be501-d2b6-489a-fbdf-d73ec0149f2a","trusted":true},"outputs":[],"source":["train_params = dict(\n","    # accumulate_grad_batches = args.gradient_accumulation_steps,\n","    # gpus = args.n_gpu,\n","    max_epochs = args.num_train_epochs,\n","    # early_stop_callback = False,\n","    precision =  '16-mixed' if args.fp_16 else 32,\n","    # amp_level = args.opt_level,\n","    # gradient_clip_val = args.max_grad_norm,\n","    # checkpoint_callback = checkpoint_callback,\n","    callbacks = [LoggingCallback()],\n","    accelerator = 'gpu', # 'auto' | 'cpu' | 'gpu' | 'tpu'\n","    devices = -1, # use all available GPUs\n","    strategy = 'auto', # 'auto' | 'dp' | 'ddp'\n",")\n","trainer = pl.Trainer(**train_params)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593,"referenced_widgets":["07299edd40e449dbb611553bdd18d396","9e17623a30df4325aa976c3fd1d80613","67f1c893b06b4df39e002cc7d56fa84f","e2345b2a9898442fabc0b14d839b1da5","d6d79f2536e0492087ab626a7f43d447","e5d333dd747349be8017d413b8ffac25","9f4509584fb042e59e8a489918fc5213","957b1c24c54b4654b138119fab702bf1","ded19473f16045be9b1fb2005a8818fa","2ec80ef499304266ae6004bc476d7873","660b5ddb00c94df69d346e91600352fb","a594cb3fe97d4fea84a8f5ade9e847f1","e2f930426c4f45d39f9c78fd3bfbfa7c","cb4ccee1fe7546908a45c1b293171117","b01ed1322e234397a442856e47ad9e75","bde9b88b5a8145c99dfa36687ed3b0c7","8732238559454df9acea95438b35c29c","8b22ca9122ba4770becfa51f024e58f7","96d5a47566be4f3dbf223bd6260e5058","3301ddd20e9b4f8f9199cf6a96fbab50","dd8aafe06c6145b0937c83e5dc96a78a","624a0b5b05f54e4f844a9caeb51962bf"]},"execution":{"iopub.execute_input":"2024-10-21T11:06:48.451055Z","iopub.status.busy":"2024-10-21T11:06:48.450313Z","iopub.status.idle":"2024-10-21T11:07:00.677706Z","shell.execute_reply":"2024-10-21T11:07:00.674839Z","shell.execute_reply.started":"2024-10-21T11:06:48.451006Z"},"id":"TWDAfg-Nvxnu","outputId":"92bb9134-f374-4bfb-fd69-27c5bfc9233f","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72ac6b6d987344c7b91721a95d48f0b8","version_major":2,"version_minor":0},"text/plain":["Training: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["W1021 11:07:00.441000 134295293105984 torch/multiprocessing/spawn.py:146] Terminating process 652 via signal SIGTERM\n"]},{"ename":"ProcessRaisedException","evalue":"\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 76, in _wrap\n    fn(i, *args)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 574, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 981, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1025, in _run_stage\n    self.fit_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n    self.advance()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n    self.advance(data_fetcher)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 252, in advance\n    batch_output = self.manual_optimization.run(kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 94, in run\n    self.advance(kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 114, in advance\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 319, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 389, in training_step\n    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 640, in __call__\n    wrapper_output = wrapper_module(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1636, in forward\n    else self._run_ddp_forward(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1454, in _run_ddp_forward\n    return self.module(*inputs, **kwargs)  # type: ignore[index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 633, in wrapped_forward\n    out = method(*_args, **_kwargs)\n  File \"/tmp/ipykernel_30/1006166733.py\", line 49, in training_step\n    loss = self._step(batch) / N\n  File \"/tmp/ipykernel_30/1006166733.py\", line 34, in _step\n    outputs = self(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_30/1006166733.py\", line 22, in forward\n    return self.model(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1703, in forward\n    encoder_outputs = self.encoder(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1107, in forward\n    layer_outputs = layer_module(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 687, in forward\n    self_attention_outputs = self.layer[0](\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 594, in forward\n    attention_output = self.SelfAttention(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 524, in forward\n    scores = torch.matmul(\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 9716 has 14.73 GiB memory in use. Of the allocated memory 14.51 GiB is allocated by PyTorch, and 16.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:46\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    138\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    147\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:189\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    187\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    188\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n","\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 76, in _wrap\n    fn(i, *args)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 574, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 981, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1025, in _run_stage\n    self.fit_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 205, in run\n    self.advance()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 363, in advance\n    self.epoch_loop.run(self._data_fetcher)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 140, in run\n    self.advance(data_fetcher)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 252, in advance\n    batch_output = self.manual_optimization.run(kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 94, in run\n    self.advance(kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 114, in advance\n    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 319, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 389, in training_step\n    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 640, in __call__\n    wrapper_output = wrapper_module(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1636, in forward\n    else self._run_ddp_forward(*inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\", line 1454, in _run_ddp_forward\n    return self.module(*inputs, **kwargs)  # type: ignore[index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 633, in wrapped_forward\n    out = method(*_args, **_kwargs)\n  File \"/tmp/ipykernel_30/1006166733.py\", line 49, in training_step\n    loss = self._step(batch) / N\n  File \"/tmp/ipykernel_30/1006166733.py\", line 34, in _step\n    outputs = self(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_30/1006166733.py\", line 22, in forward\n    return self.model(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1703, in forward\n    encoder_outputs = self.encoder(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 1107, in forward\n    layer_outputs = layer_module(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 687, in forward\n    self_attention_outputs = self.layer[0](\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 594, in forward\n    attention_output = self.SelfAttention(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py\", line 524, in forward\n    scores = torch.matmul(\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 9716 has 14.73 GiB memory in use. Of the allocated memory 14.51 GiB is allocated by PyTorch, and 16.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"]}],"source":["trainer.fit(model)"]},{"cell_type":"markdown","metadata":{"id":"SV1DLpSINOs5"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-XKbMuGNR4i","trusted":true},"outputs":[],"source":["val_set = get_dataset(tokenizer, 'val', args)\n","val_loader = DataLoader(val_set, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxfyU2ktQcxL","trusted":true},"outputs":[],"source":["def one_hot_encode_emotion(emotion):\n","    emotions = emotion.replace(' ', '').split(',')\n","    one_hot_emotion = [1 if emotion_col in emotions else 0 for emotion_col in emotion_cols]\n","    return one_hot_emotion\n","\n","y_true = []\n","y_pred = []\n","for batch in val_loader:\n","    one_hot_targets = torch.stack(batch['one_hot_target']).T.tolist()\n","\n","    output_ids = model.model.cuda().generate(input_ids=batch['source_ids'].cuda(),\n","                                          attention_mask=batch['source_mask'].cuda(),\n","                                          max_length=target_max_len)\n","    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n","    one_outputs = [one_hot_encode_emotion(output) for output in outputs]\n","\n","    assert len(one_outputs) == len(one_hot_targets)\n","    y_true += one_hot_targets\n","    y_pred += one_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIjWmNGFXUzq","trusted":true},"outputs":[],"source":["# Calculate F1 score for each type of averaging method\n","f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0.0)\n","f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n","# f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0.0)\n","# f1_samples = f1_score(y_true, y_pred, average='samples', zero_division=0.0)\n","f1_per_label = f1_score(y_true, y_pred, average=None, zero_division=0.0)\n","\n","print(f'F1 Score (Micro-Average): {f1_micro}')\n","print(f'F1 Score (Macro-Average): {f1_macro}')\n","# print(f'F1 Score (Weighted-Average): {f1_weighted}')\n","# print(f'F1 Score (Samples-Average): {f1_samples}')\n","print()\n","\n","# F1 score per label\n","for label, f1 in zip(emotion_cols, f1_per_label):\n","    print(f\"F1 Score for '{label}': {f1}\")"]},{"cell_type":"markdown","metadata":{"id":"pF0eJNHcPaIi"},"source":["# Report\n","\n","\n","\n","## Models\n","\n","| Model    \t| Total Parameters \t| Total Estimated Parameters Size \t| GPU RAM Used \t|\n","\n","|----------\t|------------------\t|---------------------------------\t|--------------\t|\n","\n","| google-t5/t5-small \t| 60.5 M           \t| ?                               \t| 2.6 GB       \t|\n","\n","| google-t5/t5-base  \t| 222 M            \t| 891.614 MB                      \t| 7.7 GB       \t|\n","\n","| google-t5/t5-large  \t| 737 M            \t| 2,950.672 MB                      \t| ?       \t|\n","\n","\n","\n","## Evaluation\n","\n","### English\n","\n","| Model    \t| F1 Score (Micro-Average) \t| F1 Score (Macro-Average) \t| F1 Score for 'anger' \t| F1 Score for 'disgust' \t| F1 Score for 'fear' \t| F1 Score for 'joy' \t| F1 Score for 'sad' \t| F1 Score for 'surprise' \t|\n","\n","|----------\t|--------------------------\t|--------------------------\t|----------------------\t|------------------------\t|---------------------\t|--------------------\t|--------------------\t|-------------------------\t|\n","\n","| google-t5/t5-small \t| 0.6123093108890058       \t| 0.4908088446307367       \t| 0.0759493670886076   \t| -                      \t| 0.7564766839378239  \t| 0.5110132158590308 \t| 0.5625             \t| 0.5481049562682215      \t|\n","\n","| google-t5/t5-base  \t| 0.6885964912280702       \t| 0.6155755742307234       \t| 0.3695652173913043   \t| -                      \t| 0.8050847457627118  \t| 0.6212121212121212 \t| 0.6522781774580336 \t| 0.6297376093294461      \t|"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["0KAEHVX_xd2F","B0V_2IghxhZ3","XCjKfs3YHzvo"],"gpuType":"T4","include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07299edd40e449dbb611553bdd18d396":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e17623a30df4325aa976c3fd1d80613","IPY_MODEL_67f1c893b06b4df39e002cc7d56fa84f","IPY_MODEL_e2345b2a9898442fabc0b14d839b1da5"],"layout":"IPY_MODEL_d6d79f2536e0492087ab626a7f43d447"}},"2ec80ef499304266ae6004bc476d7873":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3301ddd20e9b4f8f9199cf6a96fbab50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"624a0b5b05f54e4f844a9caeb51962bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"660b5ddb00c94df69d346e91600352fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67f1c893b06b4df39e002cc7d56fa84f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_957b1c24c54b4654b138119fab702bf1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ded19473f16045be9b1fb2005a8818fa","value":2}},"8732238559454df9acea95438b35c29c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b22ca9122ba4770becfa51f024e58f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"957b1c24c54b4654b138119fab702bf1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d5a47566be4f3dbf223bd6260e5058":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e17623a30df4325aa976c3fd1d80613":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d333dd747349be8017d413b8ffac25","placeholder":"​","style":"IPY_MODEL_9f4509584fb042e59e8a489918fc5213","value":"Sanity Checking DataLoader 0: 100%"}},"9f4509584fb042e59e8a489918fc5213":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a594cb3fe97d4fea84a8f5ade9e847f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2f930426c4f45d39f9c78fd3bfbfa7c","IPY_MODEL_cb4ccee1fe7546908a45c1b293171117","IPY_MODEL_b01ed1322e234397a442856e47ad9e75"],"layout":"IPY_MODEL_bde9b88b5a8145c99dfa36687ed3b0c7"}},"b01ed1322e234397a442856e47ad9e75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd8aafe06c6145b0937c83e5dc96a78a","placeholder":"​","style":"IPY_MODEL_624a0b5b05f54e4f844a9caeb51962bf","value":" 0/276 [00:00&lt;?, ?it/s]"}},"bde9b88b5a8145c99dfa36687ed3b0c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cb4ccee1fe7546908a45c1b293171117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96d5a47566be4f3dbf223bd6260e5058","max":276,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3301ddd20e9b4f8f9199cf6a96fbab50","value":0}},"d6d79f2536e0492087ab626a7f43d447":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"dd8aafe06c6145b0937c83e5dc96a78a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ded19473f16045be9b1fb2005a8818fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2345b2a9898442fabc0b14d839b1da5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ec80ef499304266ae6004bc476d7873","placeholder":"​","style":"IPY_MODEL_660b5ddb00c94df69d346e91600352fb","value":" 2/2 [00:03&lt;00:00,  0.59it/s]"}},"e2f930426c4f45d39f9c78fd3bfbfa7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8732238559454df9acea95438b35c29c","placeholder":"​","style":"IPY_MODEL_8b22ca9122ba4770becfa51f024e58f7","value":"Epoch 0:   0%"}},"e5d333dd747349be8017d413b8ffac25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":4}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install -q -U datasets transformers accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = 'sun'\n",
    "\n",
    "# hf_model_id = 'alxxtexxr/RoBERTa-Base-SE2025T11A-sun-v20250107142404' # BEST\n",
    "hf_model_id = 'alxxtexxr/RoBERTa-Base-SE2025T11A-sun-v20250108110637' \n",
    "hf_tokenizer_id = hf_model_id\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = 'track_a_sun_70_15_15_stratify_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set random seed for Torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic algorithms\n",
    "\n",
    "    # Set random seed for Transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39202d9d7f0447f2a6b509de357003fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc3dca4ef214962bb12f47f897bc5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ack_a/sun_70_15_15_stratify_v2/train.csv:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb012f7c10554086bceaa69f7cca75b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)track_a/sun_70_15_15_stratify_v2/val.csv:   0%|          | 0.00/13.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be447a8e82f47c596bda419ac73925a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)rack_a/sun_70_15_15_stratify_v2/test.csv:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f2de308665426aa0d2c505deb7a597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f814f3c809047088931009f2d0c93a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e898af107e6440c8a92bd90be85bc69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Emotions columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(hf_data_id, hf_data_config)\n",
    "\n",
    "cols = list(datasets['train'].features)\n",
    "emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion']]\n",
    "splits = [*datasets.keys()]\n",
    "\n",
    "print(\"Data columns:\", cols)\n",
    "print(\"Emotions columns:\", emotion_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to ID:\n",
      "{'biasa': 6,\n",
      " 'jijik': 1,\n",
      " 'marah': 0,\n",
      " 'sedih': 4,\n",
      " 'senang': 3,\n",
      " 'takut': 2,\n",
      " 'terkejut': 5}\n",
      "\n",
      "ID to Class:\n",
      "{0: 'marah',\n",
      " 1: 'jijik',\n",
      " 2: 'takut',\n",
      " 3: 'senang',\n",
      " 4: 'sedih',\n",
      " 5: 'terkejut',\n",
      " 6: 'biasa'}\n"
     ]
    }
   ],
   "source": [
    "class2id = {class_:id for id, class_ in enumerate(emotion_cols)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}\n",
    "\n",
    "print(\"Class to ID:\")\n",
    "pprint(class2id, width=1)\n",
    "print()\n",
    "print(\"ID to Class:\")\n",
    "pprint(id2class, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337ba4509df7487f84483cd1f8c34f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864de23657f64118b2d22b64289054ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/786k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9445d65ed65494a8a0cc84fca6e0b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/445k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f82187c4d6c489da3b4c5b8f101ead5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9aac65dd14e4d3d832ed7c75bee66a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hf_tokenizer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f73dd6bc3084573910d5cdb7bd7c73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdb2a57334e4a1aa791e869ef9e03b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2c15e5f1184f5c84683995d299d6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot_encode_emotion(emotion, emotion_cols):\n",
    "    emotions = emotion.replace(\" \", \"\").split(\",\")\n",
    "    one_hot_emotion = [1.0 if emotion_col in emotions else 0.0 for emotion_col in emotion_cols] # Ensure that the label is float, not int\n",
    "    return one_hot_emotion\n",
    "\n",
    "def preprocess_function(data):\n",
    "   text = data['text']\n",
    "   emotion = data['emotion']\n",
    "   labels = one_hot_encode_emotion(emotion, emotion_cols)\n",
    "   data = tokenizer(text, truncation=True)\n",
    "   data['labels'] = labels\n",
    "   return data\n",
    "\n",
    "tokenized_datasets = {split: datasets[split].map(preprocess_function) for split in splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ☝️Cung urang Kuningan, Pas urang waduk Darma, Kpan atuh main ka waduk Darma Dai, ??? Di antos, Aa sareng tteh Na, 🤗🤗🤗\n",
      "Emotion(s): senang\n",
      "Labels: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0] --> ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "data = tokenized_datasets['train'][5]\n",
    "\n",
    "print(\"Text:\", data['text'])\n",
    "print(\"Emotion(s):\", data['emotion'])\n",
    "print(\"Labels:\", data['labels'], '-->', emotion_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97cd8ad41ce4749a624e4cb30c95cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/810 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa3503adbec4e7e99e9e8e2ff6855e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaClassificationHead(\n",
      "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    hf_model_id, \n",
    "    num_labels=len(emotion_cols),\n",
    "    # id2label=id2class, label2id=class2id,\n",
    "    problem_type = \"multi_label_classification\",\n",
    ")\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.975 # BEST: 0.2\n",
    "\n",
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    probs = sigmoid(predictions)\n",
    "    y_pred = (probs > threshold).astype(int)\n",
    "    y_true = labels.astype(int)\n",
    "\n",
    "    # Compute F1 score for each type of averaging method\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0.0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0.0)\n",
    "    f1_samples = f1_score(y_true, y_pred, average='samples', zero_division=0.0)\n",
    "    f1_labels = f1_score(y_true, y_pred, average=None, zero_division=0.0)\n",
    "    f1_labels_dict = {f'f1_label_{emotion_cols[i]}': f1_labels[i] for i in range(len(f1_labels))}\n",
    "\n",
    "    return {\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_samples': f1_samples,\n",
    "        **f1_labels_dict,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-d538ea0c48aa>:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    # Training config\n",
    "    per_device_train_batch_size=2,\n",
    "    # num_train_epochs=3,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # Logging config for training\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "\n",
    "    # Evaluation config during training\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "\n",
    "    # Model saving config\n",
    "    # output_dir=project_name,\n",
    "    output_dir=hf_model_id,\n",
    "    save_strategy='epoch',\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation to copy:\n",
      "0.5933682563934665\t0.7615894039735099\t0.7548518302151519\t0.7122395833333333\t0.5454545454545454\t0.2222222222222222\t0.6666666666666666\t0.8571428571428571\t0.7843137254901961\t0.5777777777777777\t0.5\n",
      "\n",
      "Evaluation full results:\n",
      "{'eval_f1_label_biasa': 0.5,\n",
      " 'eval_f1_label_jijik': 0.2222222222222222,\n",
      " 'eval_f1_label_marah': 0.5454545454545454,\n",
      " 'eval_f1_label_sedih': 0.7843137254901961,\n",
      " 'eval_f1_label_senang': 0.8571428571428571,\n",
      " 'eval_f1_label_takut': 0.6666666666666666,\n",
      " 'eval_f1_label_terkejut': 0.5777777777777777,\n",
      " 'eval_f1_macro': 0.5933682563934665,\n",
      " 'eval_f1_micro': 0.7615894039735099,\n",
      " 'eval_f1_samples': 0.7122395833333333,\n",
      " 'eval_f1_weighted': 0.7548518302151519,\n",
      " 'eval_loss': 0.3361514210700989,\n",
      " 'eval_model_preparation_time': 0.0032,\n",
      " 'eval_runtime': 0.6979,\n",
      " 'eval_samples_per_second': 183.409,\n",
      " 'eval_steps_per_second': 91.705}\n"
     ]
    }
   ],
   "source": [
    "eval = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
    "\n",
    "print(\"Evaluation to copy:\")\n",
    "f1_keys = [eval_key for eval_key in eval.keys() if 'f1' in eval_key]\n",
    "for i, k in enumerate(f1_keys): print(eval[k], end=\"\\t\" if i + 1 < len(f1_keys) else \"\")\n",
    "print()\n",
    "print()\n",
    "print(\"Evaluation full results:\")\n",
    "pprint(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

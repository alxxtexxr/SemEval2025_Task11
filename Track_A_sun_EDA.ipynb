{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import unicodedata\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = 'track_a_sun_70_15_15_stratify_v2'\n",
    "\n",
    "aug_type = 'go_emotions'\n",
    "aug_data_paths = [\n",
    "    'data/go_emotions_sun/fear_single_242_comb_79_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/anger_single_237_comb_73_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/disgust_single_210_comb_35_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/sadness_single_183_comb_20_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/surprise_single_240_comb_22_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/neutral_single_210_comb_0_translated_cleaned_curated_merged_final.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set random seed for Torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic algorithms\n",
    "\n",
    "    # Set random seed for Transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d703fba88649108d60cd61338b6690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765f9847333943dfa9ded38e42c280d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94c3582e4b44de49eb32a9ba10bc6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: ['train', 'val', 'test']\n",
      "Data columns: ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Emotions columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(hf_data_id, hf_data_config)\n",
    "\n",
    "cols = list(datasets['train'].features)\n",
    "emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion']]\n",
    "splits = [*datasets.keys()]\n",
    "\n",
    "print(\"Splits:\", splits)\n",
    "print(\"Data columns:\", cols)\n",
    "print(\"Emotions columns:\", emotion_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full DF size: 924\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aya randa ker nguseup Pantun sunda meuni reuseup</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastina ath mang ku abdi shere ken knu grup + SW</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mang Fiksi t√©h urang Majalengka og√©?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedih Mang Ai kudu D Caritakeun MahüòÑüôè</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text        emotion  marah  \\\n",
       "0  Aya randa ker nguseup Pantun sunda meuni reuseup         senang      0   \n",
       "1  pastina ath mang ku abdi shere ken knu grup + SW          biasa      0   \n",
       "2              Mang Fiksi t√©h urang Majalengka og√©?         senang      0   \n",
       "3            mang dana ,uing can ngopi, kumaha ieu?         senang      0   \n",
       "4             Sedih Mang Ai kudu D Caritakeun MahüòÑüôè  senang, sedih      0   \n",
       "\n",
       "   jijik  takut  senang  sedih  terkejut  biasa  \n",
       "0      0      0       1      0         0      0  \n",
       "1      0      0       0      0         0      1  \n",
       "2      0      0       1      0         0      0  \n",
       "3      0      0       1      0         0      0  \n",
       "4      0      0       1      1         0      0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {split: pd.DataFrame(datasets[split]) for split in splits}\n",
    "full_df_ = pd.concat(df.values())\n",
    "print(\"Full DF size:\", len(full_df_))\n",
    "full_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation DF size: 1571\n",
      "Full DF size (after augmentation): 2495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aya randa ker nguseup Pantun sunda meuni reuseup</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastina ath mang ku abdi shere ken knu grup + SW</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mang Fiksi t√©h urang Majalengka og√©?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedih Mang Ai kudu D Caritakeun MahüòÑüôè</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text        emotion  marah  \\\n",
       "0  Aya randa ker nguseup Pantun sunda meuni reuseup         senang      0   \n",
       "1  pastina ath mang ku abdi shere ken knu grup + SW          biasa      0   \n",
       "2              Mang Fiksi t√©h urang Majalengka og√©?         senang      0   \n",
       "3            mang dana ,uing can ngopi, kumaha ieu?         senang      0   \n",
       "4             Sedih Mang Ai kudu D Caritakeun MahüòÑüôè  senang, sedih      0   \n",
       "\n",
       "   jijik  takut  senang  sedih  terkejut  biasa  aug_go_emotions  \n",
       "0      0      0       1      0         0      0                0  \n",
       "1      0      0       0      0         0      1                0  \n",
       "2      0      0       1      0         0      0                0  \n",
       "3      0      0       1      0         0      0                0  \n",
       "4      0      0       1      1         0      0                0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'aug_data_paths' in globals():\n",
    "    aug_df = pd.concat([pd.read_csv(aug_data_path) for aug_data_path in globals()['aug_data_paths']])\n",
    "    aug_df.drop(['id', 'curation_status', 'text', 'num_emotions'], axis=1, inplace=True)\n",
    "    aug_df.rename(columns={'text_translated': 'text'}, inplace=True)\n",
    "    aug_df['emotion'] = aug_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "    aug_df[f'aug_{aug_type}'] = 1\n",
    "    print(\"Augmentation DF size:\", len(aug_df))\n",
    "    \n",
    "    full_df_[f'aug_{aug_type}'] = 0\n",
    "    full_df = pd.concat([full_df_, aug_df])\n",
    "    print(\"Full DF size (after augmentation):\", len(full_df))\n",
    "else:\n",
    "    full_df = full_df_\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data with non-ASCII chars: 1154\n"
     ]
    }
   ],
   "source": [
    "def contains_non_ascii(text):\n",
    "    try:\n",
    "        text.encode('ascii')\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(\"Total data with non-ASCII chars:\", int(full_df['text'].apply(contains_non_ascii).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data with non-ASCII chars (after normalizing them): 0\n"
     ]
    }
   ],
   "source": [
    "def normalize_to_ascii(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "# Normalize to ASCII equivalents\n",
    "full_df['text'] = full_df['text'].apply(normalize_to_ascii)\n",
    "print(\"Total data with non-ASCII chars (after normalizing them):\", int(full_df['text'].apply(contains_non_ascii).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of emotions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "senang      677\n",
       "terkejut    509\n",
       "sedih       482\n",
       "marah       459\n",
       "jijik       418\n",
       "takut       378\n",
       "biasa       253\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Distribution of emotions:\")\n",
    "full_df[emotion_cols].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion combinations distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "senang                                  434\n",
       "sedih                                   266\n",
       "terkejut                                256\n",
       "biasa                                   253\n",
       "takut                                   248\n",
       "marah                                   246\n",
       "jijik                                   221\n",
       "senang, terkejut                        132\n",
       "marah, jijik                             94\n",
       "senang, sedih                            45\n",
       "takut, sedih                             44\n",
       "marah, sedih                             31\n",
       "sedih, terkejut                          20\n",
       "jijik, sedih                             20\n",
       "jijik, takut                             20\n",
       "takut, terkejut                          14\n",
       "marah, takut                             14\n",
       "marah, terkejut                          13\n",
       "senang, sedih, terkejut                  11\n",
       "jijik, terkejut                          10\n",
       "jijik, senang                            10\n",
       "marah, sedih, terkejut                    8\n",
       "marah, jijik, terkejut                    8\n",
       "takut, senang                             7\n",
       "takut, senang, terkejut                   7\n",
       "marah, jijik, senang                      6\n",
       "marah, jijik, sedih                       6\n",
       "marah, senang, terkejut                   6\n",
       "takut, sedih, terkejut                    5\n",
       "marah, senang, sedih                      4\n",
       "jijik, senang, terkejut                   4\n",
       "marah, jijik, takut                       4\n",
       "marah, takut, sedih                       4\n",
       "marah, jijik, sedih, terkejut             3\n",
       "jijik, sedih, terkejut                    3\n",
       "marah, jijik, senang, terkejut            2\n",
       "takut, senang, sedih                      2\n",
       "marah, jijik, takut, sedih, terkejut      2\n",
       "marah, senang                             2\n",
       "marah, takut, sedih, terkejut             2\n",
       "marah, jijik, takut, sedih                1\n",
       "jijik, takut, sedih                       1\n",
       "jijik, senang, sedih                      1\n",
       "marah, jijik, senang, sedih               1\n",
       "marah, senang, sedih, terkejut            1\n",
       "jijik, takut, senang                      1\n",
       "marah, takut, terkejut                    1\n",
       "takut, senang, sedih, terkejut            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Emotion combinations distribution:\")\n",
    "full_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of data with single emotion and combined emotions:\n",
      "\n",
      "marah          : 246 \t-> Difference from max: 7\n",
      "marah + ...    : 213\t-> Difference from max: 40\n",
      "---------------\n",
      "Total: 459\n",
      "Ratio: 115.493%\n",
      "\n",
      "jijik          : 221 \t-> Difference from max: 32\n",
      "jijik + ...    : 197\t-> Difference from max: 56\n",
      "---------------\n",
      "Total: 418\n",
      "Ratio: 112.183%\n",
      "\n",
      "takut          : 248 \t-> Difference from max: 5\n",
      "takut + ...    : 130\t-> Difference from max: 123\n",
      "---------------\n",
      "Total: 378\n",
      "Ratio: 190.769%\n",
      "\n",
      "senang         : 434 \t-> Difference from max: -181\n",
      "senang + ...   : 243\t-> Difference from max: 10\n",
      "---------------\n",
      "Total: 677\n",
      "Ratio: 178.601%\n",
      "\n",
      "sedih          : 266 \t-> Difference from max: -13\n",
      "sedih + ...    : 216\t-> Difference from max: 37\n",
      "---------------\n",
      "Total: 482\n",
      "Ratio: 123.148%\n",
      "\n",
      "terkejut       : 256 \t-> Difference from max: -3\n",
      "terkejut + ... : 253\t-> Difference from max: 0\n",
      "---------------\n",
      "Total: 509\n",
      "Ratio: 101.186%\n",
      "\n",
      "biasa          : 253 \t-> Difference from max: 0\n",
      "biasa + ...    : 0\n",
      "---------------\n",
      "Total: 253\n",
      "\n",
      "Min. single emotion total: 221\n"
     ]
    }
   ],
   "source": [
    "full_df['num_emotions'] = full_df.apply(lambda row: int(sum(row[emotion_cols].tolist())), axis=1)\n",
    "\n",
    "single_emotion_totals = [len(full_df[(full_df[emotion_col] == 1) & (full_df['num_emotions'] == 1)]) for emotion_col in emotion_cols]\n",
    "comb_emotion_totals = [len(full_df[(full_df[emotion_col] == 1) & (full_df['num_emotions'] > 1)]) for emotion_col in emotion_cols]\n",
    "\n",
    "min_single_emotion_total = float('inf')\n",
    "\n",
    "print(\"Distribution of data with single emotion and combined emotions:\\n\")\n",
    "for emotion, single_emotion_total, comb_emotion_total in zip(emotion_cols, single_emotion_totals, comb_emotion_totals):\n",
    "    if single_emotion_total < min_single_emotion_total:\n",
    "        min_single_emotion_total = single_emotion_total\n",
    "\n",
    "    diff_from_max_single = max(comb_emotion_totals) - single_emotion_total\n",
    "    diff_from_max_comb = max(comb_emotion_totals) - comb_emotion_total\n",
    "    ratio = single_emotion_total / (comb_emotion_total if comb_emotion_total else 1) * 100\n",
    "    total = single_emotion_total + comb_emotion_total\n",
    "\n",
    "    print(f\"{emotion:<15}:\", single_emotion_total, \"\\t-> Difference from max:\", diff_from_max_single, end=\"\")\n",
    "    print()\n",
    "\n",
    "    print(f\"{emotion + ' + ...':<15}:\", comb_emotion_total, end=\"\")\n",
    "    if emotion != \"biasa\":\n",
    "        print(\"\\t-> Difference from max:\", diff_from_max_comb, end=\"\")\n",
    "    print()\n",
    "\n",
    "    print(\"-\"*15)\n",
    "    print(\"Total:\", total)\n",
    "\n",
    "    if emotion != \"biasa\":\n",
    "        print(f\"Ratio: {ratio:.3f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"Min. single emotion total:\", min_single_emotion_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_dfs = []\n",
    "\n",
    "# for emotion in emotion_cols:\n",
    "#     single_emotion_df = full_df[(full_df[emotion] == 1) & (full_df['num_emotions'] == 1)]\n",
    "#     print(f\"Single {emotion} DF:\", len(single_emotion_df))\n",
    "#     single_emotion_df_balanced = single_emotion_df.sample(n=min_single_emotion_total, random_state=seed)\n",
    "#     print(f\"Single {emotion} DF (after balancing):\", len(single_emotion_df_balanced))\n",
    "\n",
    "#     comb_emotion_df = full_df[(full_df[emotion] == 1) & (full_df['num_emotions'] > 1)]\n",
    "#     print(f\"Combination {emotion} DF:\", len(comb_emotion_df))\n",
    "#     comb_emotion_df_balanced = comb_emotion_df.sample(n=min_single_emotion_total, random_state=seed) if len(comb_emotion_df) > min_single_emotion_total else comb_emotion_df\n",
    "#     print(f\"Combination {emotion} DF (after balancing):\", len(comb_emotion_df_balanced))\n",
    "\n",
    "#     total = len(single_emotion_df_balanced) + len(comb_emotion_df_balanced)\n",
    "\n",
    "#     print(\"-\" * 46)\n",
    "#     print(\"Total:\", total)\n",
    "\n",
    "#     balanced_dfs += [single_emotion_df_balanced, comb_emotion_df_balanced]\n",
    "\n",
    "#     print()\n",
    "\n",
    "# assert len(balanced_dfs) == len(emotion_cols) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_df = pd.concat(balanced_dfs)\n",
    "# balanced_df = balanced_df[~balanced_df.index.duplicated(keep='first')]\n",
    "\n",
    "# print(\"DF size:\", len(full_df))\n",
    "# print(\"DF size (after balancing)\", len(balanced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df = balanced_df.drop('num_emotions', axis=1)\n",
    "# save_df.to_csv('sun_go_emotions_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: sun_go_emotions_v2.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = 'sun_go_emotions_v2.csv'\n",
    "save_df = full_df.drop('num_emotions', axis=1)\n",
    "save_df.to_csv(save_path, index=False)\n",
    "print(\"Saved to:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

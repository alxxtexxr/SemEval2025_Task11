{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import re\n",
    "import unicodedata\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "# hf_data_config = 'track_a_sun_70_15_15_stratify_v2'\n",
    "raw_data_path = 'data/preprocessed_data_raw/track_a/sun/train.csv'\n",
    "\n",
    "aug_type = 'go_emotions'\n",
    "aug_data_paths = [\n",
    "    'data/go_emotions_sun/fear_single_242_comb_79_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/anger_single_237_comb_73_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/disgust_single_210_comb_35_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/sadness_single_183_comb_20_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/surprise_single_240_comb_22_translated_cleaned_curated_merged_final.csv',\n",
    "    'data/go_emotions_sun/neutral_single_210_comb_0_translated_cleaned_curated_merged_final.csv',\n",
    "]\n",
    "\n",
    "eng2idn_emotion_map = {\n",
    "    'anger': 'marah', \n",
    "    'disgust': 'jijik', \n",
    "    'fear': 'takut', \n",
    "    'joy': 'senang', \n",
    "    'sadness': 'sedih', \n",
    "    'surprise': 'terkejut', \n",
    "    'neutral': 'biasa',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set random seed for Torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic algorithms\n",
    "\n",
    "    # Set random seed for Transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun_train_track_a_00001</td>\n",
       "      <td>Kumaha mang fiksi engke ka sabilulungan mang s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun_train_track_a_00002</td>\n",
       "      <td>tapi domba anakan namah lain ku kuring mreun. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sun_train_track_a_00003</td>\n",
       "      <td>Aduh mang naha bet kudu penting di upload maðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sun_train_track_a_00004</td>\n",
       "      <td>pokonamah nuhun sabandungeun , kita terus ting...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sun_train_track_a_00005</td>\n",
       "      <td>Kang eta teu isin?? Apa emng tukang ngisinkeun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0  sun_train_track_a_00001  Kumaha mang fiksi engke ka sabilulungan mang s...   \n",
       "1  sun_train_track_a_00002  tapi domba anakan namah lain ku kuring mreun. ...   \n",
       "2  sun_train_track_a_00003     Aduh mang naha bet kudu penting di upload maðŸ˜‚ðŸ˜‚   \n",
       "3  sun_train_track_a_00004  pokonamah nuhun sabandungeun , kita terus ting...   \n",
       "4  sun_train_track_a_00005  Kang eta teu isin?? Apa emng tukang ngisinkeun...   \n",
       "\n",
       "   marah  jijik  takut  senang  sedih  terkejut  \n",
       "0      0      0      0       1      0         1  \n",
       "1      0      0      0       1      0         1  \n",
       "2      0      0      0       1      0         0  \n",
       "3      0      0      0       1      1         0  \n",
       "4      0      0      0       1      0         1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_ = pd.read_csv(raw_data_path)\n",
    "full_df_ = full_df_.rename(columns=eng2idn_emotion_map)\n",
    "\n",
    "full_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: ['id', 'text', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut']\n",
      "Emotions columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut']\n"
     ]
    }
   ],
   "source": [
    "# datasets = load_dataset(hf_data_id, hf_data_config)\n",
    "\n",
    "# cols = list(datasets['train'].features)\n",
    "cols = list(full_df_.columns)\n",
    "emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion', 'id']]\n",
    "# splits = [*datasets.keys()]\n",
    "\n",
    "# print(\"Splits:\", splits)\n",
    "print(\"Data columns:\", cols)\n",
    "print(\"Emotions columns:\", emotion_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = {split: pd.DataFrame(datasets[split]) for split in splits}\n",
    "# full_df_ = pd.concat(df.values())\n",
    "# print(\"Full DF size:\", len(full_df_))\n",
    "# full_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation DF size: 1571\n",
      "Full DF size (after augmentation): 2494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "      <th>biasa</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun_train_track_a_00001</td>\n",
       "      <td>Kumaha mang fiksi engke ka sabilulungan mang s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun_train_track_a_00002</td>\n",
       "      <td>tapi domba anakan namah lain ku kuring mreun. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sun_train_track_a_00003</td>\n",
       "      <td>Aduh mang naha bet kudu penting di upload maðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sun_train_track_a_00004</td>\n",
       "      <td>pokonamah nuhun sabandungeun , kita terus ting...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sun_train_track_a_00005</td>\n",
       "      <td>Kang eta teu isin?? Apa emng tukang ngisinkeun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0  sun_train_track_a_00001  Kumaha mang fiksi engke ka sabilulungan mang s...   \n",
       "1  sun_train_track_a_00002  tapi domba anakan namah lain ku kuring mreun. ...   \n",
       "2  sun_train_track_a_00003     Aduh mang naha bet kudu penting di upload maðŸ˜‚ðŸ˜‚   \n",
       "3  sun_train_track_a_00004  pokonamah nuhun sabandungeun , kita terus ting...   \n",
       "4  sun_train_track_a_00005  Kang eta teu isin?? Apa emng tukang ngisinkeun...   \n",
       "\n",
       "   marah  jijik  takut  senang  sedih  terkejut  aug_go_emotions  biasa  \\\n",
       "0      0      0      0       1      0         1                0    NaN   \n",
       "1      0      0      0       1      0         1                0    NaN   \n",
       "2      0      0      0       1      0         0                0    NaN   \n",
       "3      0      0      0       1      1         0                0    NaN   \n",
       "4      0      0      0       1      0         1                0    NaN   \n",
       "\n",
       "  emotion  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'aug_data_paths' in globals() or 'aug_type' in globals():\n",
    "    aug_df = pd.concat([pd.read_csv(aug_data_path) for aug_data_path in globals()['aug_data_paths']])\n",
    "    aug_df.drop(['id', 'curation_status', 'text', 'num_emotions'], axis=1, inplace=True)\n",
    "    aug_df.rename(columns={'text_translated': 'text'}, inplace=True)\n",
    "    aug_df['emotion'] = aug_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "    aug_df[f'aug_{globals()['aug_type']}'] = 1\n",
    "    print(\"Augmentation DF size:\", len(aug_df))\n",
    "    \n",
    "    full_df_[f'aug_{globals()['aug_type']}'] = 0\n",
    "    full_df = pd.concat([full_df_, aug_df])\n",
    "    print(\"Full DF size (after augmentation):\", len(full_df))\n",
    "else:\n",
    "    full_df = full_df_\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data with non-ASCII chars: 0\n"
     ]
    }
   ],
   "source": [
    "def remove_emojis_and_symbols(text):\n",
    "    # Regex pattern to match emojis and symbols with variation selectors\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\\U00010000-\\U0010ffff\\U00002000-\\U00002BFF\\U00002702-\\U000027B0]+\", \n",
    "        flags=re.UNICODE)\n",
    "    # Remove emojis\n",
    "    text = emoji_pattern.sub('', text)\n",
    "    # Remove any non-ASCII symbols (except regular punctuation)\n",
    "    text = ''.join(char for char in text if ord(char) < 128 and unicodedata.category(char) != 'Mn')\n",
    "    return text\n",
    "\n",
    "def contains_non_ascii(text):\n",
    "    # Remove emojis and symbols first\n",
    "    text = remove_emojis_and_symbols(text)\n",
    "    try:\n",
    "        # Check if the remaining text contains non-ASCII characters\n",
    "        text.encode('ascii')\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(\"Total data with non-ASCII chars:\", int(full_df['text'].apply(contains_non_ascii).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data with non-ASCII chars (after normalizing them): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "      <th>biasa</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun_train_track_a_00001</td>\n",
       "      <td>Kumaha mang fiksi engke ka sabilulungan mang s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun_train_track_a_00002</td>\n",
       "      <td>tapi domba anakan namah lain ku kuring mreun. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sun_train_track_a_00003</td>\n",
       "      <td>Aduh mang naha bet kudu penting di upload maðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sun_train_track_a_00004</td>\n",
       "      <td>pokonamah nuhun sabandungeun , kita terus ting...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sun_train_track_a_00005</td>\n",
       "      <td>Kang eta teu isin?? Apa emng tukang ngisinkeun...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0  sun_train_track_a_00001  Kumaha mang fiksi engke ka sabilulungan mang s...   \n",
       "1  sun_train_track_a_00002  tapi domba anakan namah lain ku kuring mreun. ...   \n",
       "2  sun_train_track_a_00003     Aduh mang naha bet kudu penting di upload maðŸ˜‚ðŸ˜‚   \n",
       "3  sun_train_track_a_00004  pokonamah nuhun sabandungeun , kita terus ting...   \n",
       "4  sun_train_track_a_00005  Kang eta teu isin?? Apa emng tukang ngisinkeun...   \n",
       "\n",
       "   marah  jijik  takut  senang  sedih  terkejut  aug_go_emotions  biasa  \\\n",
       "0      0      0      0       1      0         1                0    NaN   \n",
       "1      0      0      0       1      0         1                0    NaN   \n",
       "2      0      0      0       1      0         0                0    NaN   \n",
       "3      0      0      0       1      1         0                0    NaN   \n",
       "4      0      0      0       1      0         1                0    NaN   \n",
       "\n",
       "  emotion  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_to_ascii(text):\n",
    "    # Normalize the text to decompose accented characters\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    # Remove only combining marks (like accents) while keeping emojis and other symbols\n",
    "    text = ''.join(char for char in text if not unicodedata.combining(char))\n",
    "    return text\n",
    "\n",
    "# Normalize to ASCII equivalents\n",
    "full_df['text'] = full_df['text'].apply(normalize_to_ascii)\n",
    "print(\"Total data with non-ASCII chars (after normalizing them):\", int(full_df['text'].apply(contains_non_ascii).sum()))\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of emotions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "senang      677\n",
       "terkejut    509\n",
       "sedih       482\n",
       "marah       458\n",
       "jijik       417\n",
       "takut       378\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Distribution of emotions:\")\n",
    "full_df[emotion_cols].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion combinations distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "takut                            243\n",
       "terkejut                         240\n",
       "marah                            238\n",
       "jijik                            220\n",
       "                                 210\n",
       "sedih                            184\n",
       "marah, jijik                      79\n",
       "takut, sedih                      33\n",
       "marah, sedih                      22\n",
       "jijik, takut                      20\n",
       "jijik, sedih                      15\n",
       "marah, takut                      13\n",
       "marah, terkejut                   13\n",
       "takut, terkejut                   12\n",
       "jijik, terkejut                    8\n",
       "sedih, terkejut                    4\n",
       "senang, sedih                      3\n",
       "marah, jijik, takut                3\n",
       "marah, takut, sedih, terkejut      2\n",
       "marah, takut, sedih                2\n",
       "marah, jijik, takut, sedih         1\n",
       "marah, jijik, sedih, terkejut      1\n",
       "jijik, takut, sedih                1\n",
       "takut, senang, terkejut            1\n",
       "senang, terkejut                   1\n",
       "jijik, sedih, terkejut             1\n",
       "marah, jijik, sedih                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Emotion combinations distribution:\")\n",
    "full_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of data with single emotion and combined emotions:\n",
      "\n",
      "marah          : 246 \t-> Difference from max: 7\n",
      "marah + ...    : 212\t-> Difference from max: 41\n",
      "---------------\n",
      "Total: 458\n",
      "Ratio: 116.038%\n",
      "\n",
      "jijik          : 221 \t-> Difference from max: 32\n",
      "jijik + ...    : 196\t-> Difference from max: 57\n",
      "---------------\n",
      "Total: 417\n",
      "Ratio: 112.755%\n",
      "\n",
      "takut          : 248 \t-> Difference from max: 5\n",
      "takut + ...    : 130\t-> Difference from max: 123\n",
      "---------------\n",
      "Total: 378\n",
      "Ratio: 190.769%\n",
      "\n",
      "senang         : 434 \t-> Difference from max: -181\n",
      "senang + ...   : 243\t-> Difference from max: 10\n",
      "---------------\n",
      "Total: 677\n",
      "Ratio: 178.601%\n",
      "\n",
      "sedih          : 266 \t-> Difference from max: -13\n",
      "sedih + ...    : 216\t-> Difference from max: 37\n",
      "---------------\n",
      "Total: 482\n",
      "Ratio: 123.148%\n",
      "\n",
      "terkejut       : 256 \t-> Difference from max: -3\n",
      "terkejut + ... : 253\t-> Difference from max: 0\n",
      "---------------\n",
      "Total: 509\n",
      "Ratio: 101.186%\n",
      "\n",
      "Min. single emotion total: 221\n"
     ]
    }
   ],
   "source": [
    "full_df['num_emotions'] = full_df.apply(lambda row: int(sum(row[emotion_cols].tolist())), axis=1)\n",
    "\n",
    "single_emotion_totals = [len(full_df[(full_df[emotion_col] == 1) & (full_df['num_emotions'] == 1)]) for emotion_col in emotion_cols]\n",
    "comb_emotion_totals = [len(full_df[(full_df[emotion_col] == 1) & (full_df['num_emotions'] > 1)]) for emotion_col in emotion_cols]\n",
    "\n",
    "min_single_emotion_total = float('inf')\n",
    "\n",
    "print(\"Distribution of data with single emotion and combined emotions:\\n\")\n",
    "for emotion, single_emotion_total, comb_emotion_total in zip(emotion_cols, single_emotion_totals, comb_emotion_totals):\n",
    "    if single_emotion_total < min_single_emotion_total:\n",
    "        min_single_emotion_total = single_emotion_total\n",
    "\n",
    "    diff_from_max_single = max(comb_emotion_totals) - single_emotion_total\n",
    "    diff_from_max_comb = max(comb_emotion_totals) - comb_emotion_total\n",
    "    ratio = single_emotion_total / (comb_emotion_total if comb_emotion_total else 1) * 100\n",
    "    total = single_emotion_total + comb_emotion_total\n",
    "\n",
    "    print(f\"{emotion:<15}:\", single_emotion_total, \"\\t-> Difference from max:\", diff_from_max_single, end=\"\")\n",
    "    print()\n",
    "\n",
    "    print(f\"{emotion + ' + ...':<15}:\", comb_emotion_total, end=\"\")\n",
    "    if emotion != \"biasa\":\n",
    "        print(\"\\t-> Difference from max:\", diff_from_max_comb, end=\"\")\n",
    "    print()\n",
    "\n",
    "    print(\"-\"*15)\n",
    "    print(\"Total:\", total)\n",
    "\n",
    "    if emotion != \"biasa\":\n",
    "        print(f\"Ratio: {ratio:.3f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"Min. single emotion total:\", min_single_emotion_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_dfs = []\n",
    "\n",
    "# for emotion in emotion_cols:\n",
    "#     single_emotion_df = full_df[(full_df[emotion] == 1) & (full_df['num_emotions'] == 1)]\n",
    "#     print(f\"Single {emotion} DF:\", len(single_emotion_df))\n",
    "#     single_emotion_df_balanced = single_emotion_df.sample(n=min_single_emotion_total, random_state=seed)\n",
    "#     print(f\"Single {emotion} DF (after balancing):\", len(single_emotion_df_balanced))\n",
    "\n",
    "#     comb_emotion_df = full_df[(full_df[emotion] == 1) & (full_df['num_emotions'] > 1)]\n",
    "#     print(f\"Combination {emotion} DF:\", len(comb_emotion_df))\n",
    "#     comb_emotion_df_balanced = comb_emotion_df.sample(n=min_single_emotion_total, random_state=seed) if len(comb_emotion_df) > min_single_emotion_total else comb_emotion_df\n",
    "#     print(f\"Combination {emotion} DF (after balancing):\", len(comb_emotion_df_balanced))\n",
    "\n",
    "#     total = len(single_emotion_df_balanced) + len(comb_emotion_df_balanced)\n",
    "\n",
    "#     print(\"-\" * 46)\n",
    "#     print(\"Total:\", total)\n",
    "\n",
    "#     balanced_dfs += [single_emotion_df_balanced, comb_emotion_df_balanced]\n",
    "\n",
    "#     print()\n",
    "\n",
    "# assert len(balanced_dfs) == len(emotion_cols) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_df = pd.concat(balanced_dfs)\n",
    "# balanced_df = balanced_df[~balanced_df.index.duplicated(keep='first')]\n",
    "\n",
    "# print(\"DF size:\", len(full_df))\n",
    "# print(\"DF size (after balancing)\", len(balanced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df = balanced_df.drop('num_emotions', axis=1)\n",
    "# save_df.to_csv('sun_go_emotions_balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: sun_go_emotions_v3.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = 'sun_go_emotions_v3.csv'\n",
    "save_df = full_df.drop('num_emotions', axis=1)\n",
    "save_df.to_csv(save_path, index=False)\n",
    "print(\"Saved to:\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

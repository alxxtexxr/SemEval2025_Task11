{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face dataset config: sun_go_emotions_80_10_10\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "# lang = 'sun'\n",
    "lang = 'sun_go_emotions'\n",
    "\n",
    "# raw_data_dir = './data/public_data/'\n",
    "raw_data_dir = './data/augmented_data/'\n",
    "raw_data_path = os.path.join(raw_data_dir, f'train/track_a/sun_go_emotions_v2.csv')\n",
    "preprocessed_data_dir = './data/preprocessed_data/'\n",
    "\n",
    "split_sizes = [0.8, 0.1, 0.1]\n",
    "assert sum(split_sizes) == 1.0\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = lang + '_' + '_'.join([str(int(split_size * 100)) for split_size in split_sizes])\n",
    "print(\"Hugging Face dataset config:\", hf_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw DF length: 2495\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aya randa ker nguseup Pantun sunda meuni reuseup</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastina ath mang ku abdi shere ken knu grup + SW</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mang Fiksi teh urang Majalengka oge?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedih Mang Ai kudu D Caritakeun Mah</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>Nya, anjeun geus meakkeun dua jam.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>Kuring teu maca artikel anjeun tapi kuring nya...</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>Aya sababaraha variasi sapanjang taun.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Kuring mendakan sahanteuna hiji putri duyung u...</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>teu aya anu husus. eta beda-beda.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2495 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        emotion  marah  \\\n",
       "0      Aya randa ker nguseup Pantun sunda meuni reuseup         senang      0   \n",
       "1      pastina ath mang ku abdi shere ken knu grup + SW          biasa      0   \n",
       "2                  Mang Fiksi teh urang Majalengka oge?         senang      0   \n",
       "3                mang dana ,uing can ngopi, kumaha ieu?         senang      0   \n",
       "4                   Sedih Mang Ai kudu D Caritakeun Mah  senang, sedih      0   \n",
       "...                                                 ...            ...    ...   \n",
       "2490                 Nya, anjeun geus meakkeun dua jam.          biasa      0   \n",
       "2491  Kuring teu maca artikel anjeun tapi kuring nya...          biasa      0   \n",
       "2492             Aya sababaraha variasi sapanjang taun.          biasa      0   \n",
       "2493  Kuring mendakan sahanteuna hiji putri duyung u...          biasa      0   \n",
       "2494                  teu aya anu husus. eta beda-beda.          biasa      0   \n",
       "\n",
       "      jijik  takut  senang  sedih  terkejut  biasa  aug_go_emotions  \n",
       "0         0      0       1      0         0      0                0  \n",
       "1         0      0       0      0         0      1                0  \n",
       "2         0      0       1      0         0      0                0  \n",
       "3         0      0       1      0         0      0                0  \n",
       "4         0      0       1      1         0      0                0  \n",
       "...     ...    ...     ...    ...       ...    ...              ...  \n",
       "2490      0      0       0      0         0      1                1  \n",
       "2491      0      0       0      0         0      1                1  \n",
       "2492      0      0       0      0         0      1                1  \n",
       "2493      0      0       0      0         0      1                1  \n",
       "2494      0      0       0      0         0      1                1  \n",
       "\n",
       "[2495 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(raw_data_path)\n",
    "print(\"Raw DF length:\", len(df))\n",
    "print()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Augmentation columns: ['aug_go_emotions']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aya randa ker nguseup Pantun sunda meuni reuseup</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastina ath mang ku abdi shere ken knu grup + SW</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mang Fiksi teh urang Majalengka oge?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedih Mang Ai kudu D Caritakeun Mah</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text        emotion  marah  \\\n",
       "0  Aya randa ker nguseup Pantun sunda meuni reuseup         senang      0   \n",
       "1  pastina ath mang ku abdi shere ken knu grup + SW          biasa      0   \n",
       "2              Mang Fiksi teh urang Majalengka oge?         senang      0   \n",
       "3            mang dana ,uing can ngopi, kumaha ieu?         senang      0   \n",
       "4               Sedih Mang Ai kudu D Caritakeun Mah  senang, sedih      0   \n",
       "\n",
       "   jijik  takut  senang  sedih  terkejut  biasa  aug_go_emotions  \n",
       "0      0      0       1      0         0      0                0  \n",
       "1      0      0       0      0         0      1                0  \n",
       "2      0      0       1      0         0      0                0  \n",
       "3      0      0       1      0         0      0                0  \n",
       "4      0      0       1      1         0      0                0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_col_map = {\n",
    "    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n",
    "    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': 'überraschung' },\n",
    "    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "    'sun_go_emotions': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "}\n",
    "emotion_cols = list(emotion_col_map[lang].values())\n",
    "\n",
    "neutral_emotion_map = {\n",
    "    'eng': 'neutral',\n",
    "    'deu': 'neutral',\n",
    "    'sun': 'biasa',\n",
    "    'sun_go_emotions': 'biasa',\n",
    "}\n",
    "neutral_emotion = neutral_emotion_map[lang]\n",
    "\n",
    "# Rename emotion columns\n",
    "df = df.rename(columns=emotion_col_map[lang])\n",
    "\n",
    "# Create 'emotion' column by combining the positive emotions\n",
    "df['emotion'] = df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "df['emotion'] = df['emotion'].replace('', neutral_emotion) # Fill neutral emotion\n",
    "\n",
    "# Create neutral emotion column\n",
    "df[neutral_emotion_map[lang]] = (df['emotion'] == neutral_emotion).astype(int)\n",
    "emotion_cols += [neutral_emotion]\n",
    "print(\"Emotion columns:\", emotion_cols)\n",
    "\n",
    "# Get augmentation columns\n",
    "aug_columns = [col for col in df.columns if col.startswith('aug_')]\n",
    "print(\"Augmentation columns:\", aug_columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF non-augmented size: 924\n",
      "DF augmented size: 1571\n",
      "DF total size: 2495\n"
     ]
    }
   ],
   "source": [
    "df_non_aug = df[df['aug_go_emotions'] == 0]\n",
    "df_aug = df[df['aug_go_emotions'] == 1]\n",
    "\n",
    "print(\"DF non-augmented size:\", len(df_non_aug))\n",
    "print(\"DF augmented size:\", len(df_aug))\n",
    "print(\"DF total size:\", len(df_aug) + len(df_non_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF non-augmented size: 753 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa', 'aug_go_emotions', 'stratify']\n",
      "Validation DF non-augmented size: 85 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa', 'aug_go_emotions', 'stratify']\n",
      "Testing DF non-augmented size: 86 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa', 'aug_go_emotions', 'stratify']\n",
      "\n",
      "Training DF augmented size: 1261 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa', 'aug_go_emotions', 'stratify']\n",
      "Validation DF augmented size: 155 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa', 'aug_go_emotions', 'stratify']\n",
      "Testing DF augmented size: 155 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa', 'aug_go_emotions', 'stratify']\n",
      "\n",
      "Training non-augmented : augmented ratio: 37.39% : 62.61%\n",
      "Validation non-augmented : augmented ratio: 35.42% : 64.58%\n",
      "Testing non-augmented : augmented ratio: 35.68% : 64.32%\n",
      "\n",
      "Training DF size: 2014 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Validation DF size: 240 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Testing DF size: 241 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    }
   ],
   "source": [
    "# Stratified split the data\n",
    "def create_stratify_col(df):\n",
    "    # Create 'stratify' column for stratified split\n",
    "    df.loc[:, 'stratify'] = df['emotion']\n",
    "\n",
    "    # Identify classes with only one member\n",
    "    single_class = df['emotion'].value_counts()[df['emotion'].value_counts() <= 2].index\n",
    "\n",
    "    # Assign a dummy value for the 'stratify' column for these classes\n",
    "    df.loc[df['emotion'].isin(single_class), 'stratify'] = 'dummy'\n",
    "\n",
    "def stratify(df):\n",
    "    create_stratify_col(df)\n",
    "\n",
    "    emotion_lt_7 = df['emotion'].value_counts()[(df['emotion'].value_counts() < 7)].index.tolist()\n",
    "    emotion_lt_7_cond = df['emotion'].isin(emotion_lt_7)\n",
    "    df_emotion_lt_7 = df[emotion_lt_7_cond]\n",
    "    df = df[~emotion_lt_7_cond]\n",
    "\n",
    "    # Split training DF into training and validation DFs\n",
    "    if len(split_sizes) == 3:\n",
    "        train_df, val_test_df = train_test_split(df,\n",
    "                                                train_size=split_sizes[0],\n",
    "                                                stratify=df['stratify'],\n",
    "                                                random_state=seed)\n",
    "        create_stratify_col(val_test_df)\n",
    "        test_size = split_sizes[-1]/(split_sizes[1] + split_sizes[-1])\n",
    "        val_df, test_df = train_test_split(val_test_df,\n",
    "                                        test_size=test_size,\n",
    "                                        stratify=val_test_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "\n",
    "    train_df = pd.concat([train_df, df_emotion_lt_7])\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df_non_aug, val_df_non_aug, test_df_non_aug = stratify(df_non_aug)\n",
    "print(\"Training DF non-augmented size:\", len(train_df_non_aug), \"-->\", train_df_non_aug.columns.tolist())\n",
    "print(\"Validation DF non-augmented size:\", len(val_df_non_aug), \"-->\", val_df_non_aug.columns.tolist())\n",
    "print(\"Testing DF non-augmented size:\", len(test_df_non_aug), \"-->\", test_df_non_aug.columns.tolist())\n",
    "print()\n",
    "\n",
    "train_df_aug, val_df_aug, test_df_aug = stratify(df_aug)\n",
    "print(\"Training DF augmented size:\", len(train_df_aug), \"-->\", train_df_aug.columns.tolist())\n",
    "print(\"Validation DF augmented size:\", len(val_df_aug), \"-->\", val_df_aug.columns.tolist())\n",
    "print(\"Testing DF augmented size:\", len(test_df_aug), \"-->\", test_df_aug.columns.tolist())\n",
    "print()\n",
    "\n",
    "print(f\"Training non-augmented : augmented ratio: {(len(train_df_non_aug)/(len(train_df_non_aug) + len(train_df_aug))*100):.2f}% : {(len(train_df_aug)/(len(train_df_non_aug) + len(train_df_aug))*100):.2f}%\")\n",
    "print(f\"Validation non-augmented : augmented ratio: {(len(val_df_non_aug)/(len(val_df_non_aug) + len(val_df_aug))*100):.2f}% : {(len(val_df_aug)/(len(val_df_non_aug) + len(val_df_aug))*100):.2f}%\")\n",
    "print(f\"Testing non-augmented : augmented ratio: {(len(test_df_non_aug)/(len(test_df_non_aug) + len(test_df_aug))*100):.2f}% : {(len(test_df_aug)/(len(test_df_non_aug) + len(test_df_aug))*100):.2f}%\")\n",
    "print()\n",
    "\n",
    "train_df = pd.concat([train_df_non_aug, train_df_aug], axis=0)[['text', 'emotion'] + emotion_cols]\n",
    "val_df = pd.concat([val_df_non_aug, val_df_aug], axis=0)[['text', 'emotion'] + emotion_cols]\n",
    "test_df = pd.concat([test_df_non_aug, test_df_aug], axis=0)[['text', 'emotion'] + emotion_cols]\n",
    "print(\"Training DF size:\", len(train_df), \"-->\", train_df.columns.tolist())\n",
    "print(\"Validation DF size:\", len(val_df), \"-->\", val_df.columns.tolist())\n",
    "print(\"Testing DF size:\", len(test_df), \"-->\", test_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "senang                     44\n",
       "sedih                      28\n",
       "biasa                      26\n",
       "terkejut                   25\n",
       "marah                      25\n",
       "takut                      24\n",
       "jijik                      22\n",
       "senang, terkejut           13\n",
       "marah, jijik                9\n",
       "senang, sedih               4\n",
       "takut, sedih                4\n",
       "marah, sedih                3\n",
       "senang, sedih, terkejut     2\n",
       "marah, jijik, terkejut      2\n",
       "marah, takut                2\n",
       "jijik, takut                2\n",
       "marah, terkejut             2\n",
       "sedih, terkejut             1\n",
       "marah, sedih, terkejut      1\n",
       "takut, terkejut             1\n",
       "jijik, sedih                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/preprocessed_data/track_a/sun_go_emotions_80_10_10\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(preprocessed_data_dir, 'track_a', hf_data_config)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df.to_csv(os.path.join(save_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'), index=False)\n",
    "# dev_df.to_csv(os.path.join(save_dir, 'dev.csv'), index=False)\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset/commit/cfc0870a57a716a8d6052c6fd4fbee555c5ac30d', commit_message='Upload folder using huggingface_hub', commit_description='', oid='cfc0870a57a716a8d6052c6fd4fbee555c5ac30d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='alxxtexxr/SemEval2025-Task11-Dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=hf_data_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data/track_a', hf_data_config),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

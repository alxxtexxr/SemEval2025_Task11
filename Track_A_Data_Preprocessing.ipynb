{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face dataset config: sun_go_emotions_70_15_15_v2\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "# lang = 'sun'\n",
    "lang = 'sun_go_emotions'\n",
    "\n",
    "# raw_data_dir = './data/public_data/'\n",
    "raw_data_dir = './data/augmented_data/'\n",
    "raw_data_path = os.path.join(raw_data_dir, f'train/track_a/sun_go_emotions_v2.csv')\n",
    "preprocessed_data_dir = './data/preprocessed_data/'\n",
    "\n",
    "split_sizes = [0.7, 0.15, 0.15]\n",
    "assert sum(split_sizes) == 1.0\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = lang + '_' + '_'.join([str(int(split_size * 100)) for split_size in split_sizes]) + '_v2'\n",
    "print(\"Hugging Face dataset config:\", hf_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length: 4066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngobrol ka kolotna meureun lamun eta pilihan.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urang mah sok bingung ka batur anu ngomong nye...</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Bedana teh lantaran abdi pantes narimana.\" Ie...</td>\n",
       "      <td>marah</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aranjeun teh barudak teuweul anu ambek sabab m...</td>\n",
       "      <td>marah, jijik</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anjeun teu nyaho naon fakta teh?</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>Nya, anjeun geus meakkeun dua jam.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>Kuring teu maca artikel anjeun tapi kuring nya...</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>Aya sababaraha variasi sapanjang taun.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>Kuring mendakan sahanteuna hiji putri duyung u...</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>teu aya anu husus. eta beda-beda.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4066 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        emotion  marah  \\\n",
       "0         Ngobrol ka kolotna meureun lamun eta pilihan.          biasa      0   \n",
       "1     Urang mah sok bingung ka batur anu ngomong nye...  senang, sedih      0   \n",
       "2     \"Bedana teh lantaran abdi pantes narimana.\" Ie...          marah      1   \n",
       "3     Aranjeun teh barudak teuweul anu ambek sabab m...   marah, jijik      1   \n",
       "4                      Anjeun teu nyaho naon fakta teh?          biasa      0   \n",
       "...                                                 ...            ...    ...   \n",
       "4061                 Nya, anjeun geus meakkeun dua jam.          biasa      0   \n",
       "4062  Kuring teu maca artikel anjeun tapi kuring nya...          biasa      0   \n",
       "4063             Aya sababaraha variasi sapanjang taun.          biasa      0   \n",
       "4064  Kuring mendakan sahanteuna hiji putri duyung u...          biasa      0   \n",
       "4065                  teu aya anu husus. eta beda-beda.          biasa      0   \n",
       "\n",
       "      jijik  takut  senang  sedih  terkejut  biasa  aug_go_emotions  \n",
       "0         0      0       0      0         0      1                0  \n",
       "1         0      0       1      1         0      0                0  \n",
       "2         0      0       0      0         0      0                0  \n",
       "3         1      0       0      0         0      0                0  \n",
       "4         0      0       0      0         0      1                0  \n",
       "...     ...    ...     ...    ...       ...    ...              ...  \n",
       "4061      0      0       0      0         0      1                0  \n",
       "4062      0      0       0      0         0      1                0  \n",
       "4063      0      0       0      0         0      1                0  \n",
       "4064      0      0       0      0         0      1                0  \n",
       "4065      0      0       0      0         0      1                0  \n",
       "\n",
       "[4066 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(raw_data_path)\n",
    "print(\"Training DF length:\", len(train_df))\n",
    "print()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Augmentation columns: ['aug_go_emotions']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "      <th>aug_go_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngobrol ka kolotna meureun lamun eta pilihan.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urang mah sok bingung ka batur anu ngomong nye...</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Bedana teh lantaran abdi pantes narimana.\" Ie...</td>\n",
       "      <td>marah</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aranjeun teh barudak teuweul anu ambek sabab m...</td>\n",
       "      <td>marah, jijik</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anjeun teu nyaho naon fakta teh?</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        emotion  marah  \\\n",
       "0      Ngobrol ka kolotna meureun lamun eta pilihan.          biasa      0   \n",
       "1  Urang mah sok bingung ka batur anu ngomong nye...  senang, sedih      0   \n",
       "2  \"Bedana teh lantaran abdi pantes narimana.\" Ie...          marah      1   \n",
       "3  Aranjeun teh barudak teuweul anu ambek sabab m...   marah, jijik      1   \n",
       "4                   Anjeun teu nyaho naon fakta teh?          biasa      0   \n",
       "\n",
       "   jijik  takut  senang  sedih  terkejut  biasa  aug_go_emotions  \n",
       "0      0      0       0      0         0      1                0  \n",
       "1      0      0       1      1         0      0                0  \n",
       "2      0      0       0      0         0      0                0  \n",
       "3      1      0       0      0         0      0                0  \n",
       "4      0      0       0      0         0      1                0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_col_map = {\n",
    "    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n",
    "    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': 'Ã¼berraschung' },\n",
    "    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "    'sun_go_emotions': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "}\n",
    "emotion_cols = list(emotion_col_map[lang].values())\n",
    "\n",
    "neutral_emotion_map = {\n",
    "    'eng': 'neutral',\n",
    "    'deu': 'neutral',\n",
    "    'sun': 'biasa',\n",
    "    'sun_go_emotions': 'biasa',\n",
    "}\n",
    "neutral_emotion = neutral_emotion_map[lang]\n",
    "\n",
    "# Rename emotion columns\n",
    "train_df = train_df.rename(columns=emotion_col_map[lang])\n",
    "\n",
    "# Create 'emotion' column by combining the positive emotions\n",
    "train_df['emotion'] = train_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "train_df['emotion'] = train_df['emotion'].replace('', neutral_emotion) # Fill neutral emotion\n",
    "\n",
    "# Create neutral emotion column\n",
    "train_df[neutral_emotion_map[lang]] = (train_df['emotion'] == neutral_emotion).astype(int)\n",
    "emotion_cols += [neutral_emotion]\n",
    "print(\"Emotion columns:\", emotion_cols)\n",
    "\n",
    "# Get augmentation columns\n",
    "aug_columns = [col for col in train_df.columns if col.startswith('aug_')]\n",
    "print(\"Augmentation columns:\", aug_columns)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (3295533728.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[78], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    return\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Stratified split the data\n",
    "def create_stratify_col(df):\n",
    "    # Create 'stratify' column for stratified split\n",
    "    df['stratify'] = df['emotion']\n",
    "\n",
    "    # Identify classes with only one member\n",
    "    single_class = df['emotion'].value_counts()[df['emotion'].value_counts() == 1].index\n",
    "\n",
    "    # Assign a dummy value for the 'stratify' column for these classes\n",
    "    df.loc[df['emotion'].isin(single_class), 'stratify'] = 'dummy'\n",
    "\n",
    "create_stratify_col(train_df)\n",
    "\n",
    "emotion_lt_7 = train_df['emotion'].value_counts()[(train_df['emotion'].value_counts() < 7)].index.tolist()\n",
    "emotion_lt_7_cond = train_df['emotion'].isin(emotion_lt_7)\n",
    "train_df_emotion_lt_7 = train_df[emotion_lt_7_cond]\n",
    "train_df = train_df[~emotion_lt_7_cond]\n",
    "\n",
    "# Divide DF into non-augmented and augmented DF\n",
    "train_df_non_aug = train_df[(train_df[aug_columns] == 0).all(axis=1)]\n",
    "train_df_aug = train_df[(train_df[aug_columns] == 1).all(axis=1)]\n",
    "\n",
    "# Create testing DF from non-augmented DF\n",
    "test_size = split_sizes[-1] * (len(train_df_emotion_lt_7) + len(train_df))\n",
    "train_df_non_aug_, test_df = train_test_split(train_df_non_aug[['text', 'emotion'] + emotion_cols],\n",
    "                                              test_size=test_size,\n",
    "                                              stratify=train_df_non_aug['stratify'],\n",
    "                                              random_state=seed)\n",
    "\n",
    "train_df_ = pd.concat(train_df_non_aug_, train_df_aug)\n",
    "\n",
    "create_stratify_col(train_df_)\n",
    "\n",
    "# Split training DF into training and validation DFs\n",
    "train_df__, val_df = train_test_split(train_df_[['text', 'emotion'] + emotion_cols],\n",
    "                                      test_size=test_size,\n",
    "                                      stratify=train_df_['stratify'],\n",
    "                                      random_state=seed)\n",
    "\n",
    "# create_stratify_col(val_test_df)\n",
    "# test_size = split_sizes[-1]/(split_sizes[1] + split_sizes[-1])\n",
    "# val_df, test_df = train_test_split(val_test_df[['text', 'emotion'] + emotion_cols],\n",
    "#                                     test_size=test_size,\n",
    "#                                     stratify=val_test_df['stratify'],\n",
    "#                                     random_state=seed)\n",
    "\n",
    "print(\"Training DF length (splitted):\", len(train_df__), \"-->\", train_df__.columns.tolist())\n",
    "print(\"Validation DF length:\", len(val_df), \"-->\", val_df.columns.tolist())\n",
    "print(\"Testing DF length:\", len(test_df), \"-->\", test_df.columns.tolist())\n",
    "\n",
    "train_df__ = pd.concat([train_df__, train_df_emotion_lt_7[['text', 'emotion'] + emotion_cols]])\n",
    "\n",
    "# dev_df = pd.read_csv(os.path.join(raw_data_dir, f'dev/track_a/{lang}_a.csv'))\n",
    "# dev_df = dev_df.rename(columns=emotion_col_map[lang])\n",
    "# dev_df['emotion'] = None\n",
    "# dev_df = dev_df[['text', 'emotion'] + emotion_cols]\n",
    "# print(\"Dev. DF length:\", len(dev_df), \"-->\", dev_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "marah                      32\n",
       "jijik                      27\n",
       "takut                      25\n",
       "senang                     22\n",
       "sedih                      21\n",
       "biasa                      19\n",
       "terkejut                   19\n",
       "marah, jijik               13\n",
       "senang, terkejut           12\n",
       "takut, sedih                5\n",
       "senang, sedih               5\n",
       "marah, sedih                5\n",
       "jijik, takut                3\n",
       "marah, terkejut             2\n",
       "marah, takut                2\n",
       "takut, terkejut             2\n",
       "jijik, sedih                2\n",
       "sedih, terkejut             1\n",
       "jijik, terkejut             1\n",
       "marah, jijik, terkejut      1\n",
       "marah, sedih, terkejut      1\n",
       "senang, sedih, terkejut     1\n",
       "jijik, senang               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/preprocessed_data/track_a/sun_go_emotions_70_15_15_balanced\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(preprocessed_data_dir, 'track_a', hf_data_config)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df_.to_csv(os.path.join(save_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'), index=False)\n",
    "# dev_df.to_csv(os.path.join(save_dir, 'dev.csv'), index=False)\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset/commit/9dd9c464be247d43d5843313f0596bcca9c4d62d', commit_message='Upload folder using huggingface_hub', commit_description='', oid='9dd9c464be247d43d5843313f0596bcca9c4d62d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='alxxtexxr/SemEval2025-Task11-Dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=hf_data_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data/track_a', hf_data_config),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

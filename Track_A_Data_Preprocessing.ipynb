{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face dataset config: sun_70_15_15_stratify_v2\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "# lang = 'eng'\n",
    "lang = 'sun'\n",
    "raw_data_dir = './data/public_data/'\n",
    "preprocessed_data_dir = './data/preprocessed_data/'\n",
    "split_sizes = [0.7, 0.15, 0.15]\n",
    "assert sum(split_sizes) == 1.0\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = lang + '_' + '_'.join([str(int(split_size * 100)) for split_size in split_sizes]) + '_stratify_v2'\n",
    "print(\"Hugging Face dataset config:\", hf_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length: 924\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun_train_track_a_00001</td>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun_train_track_a_00002</td>\n",
       "      <td>Siap teu nanaon nuhun pisan tos nonton,kumaha ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sun_train_track_a_00003</td>\n",
       "      <td>ulin ka tasik mang, urang hayang asup kana kon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sun_train_track_a_00004</td>\n",
       "      <td>Pokona bakalan sukses akang¬≤ ieu mah üëçüëçüëç</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sun_train_track_a_00005</td>\n",
       "      <td>FIKSI mang dana kunn tara nyieun vidio deui ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>sun_train_track_a_00920</td>\n",
       "      <td>bener mang teu karasa nya waktu duh kmh sehat?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>sun_train_track_a_00921</td>\n",
       "      <td>Terang ieu chenel ka akang willi ti stt wa rer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>sun_train_track_a_00922</td>\n",
       "      <td>Sabaraha gereget jadi orang sunda Kamari urang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>sun_train_track_a_00923</td>\n",
       "      <td>Yg nunggu vidio baru ngacung, ‚òù Naha jarang up...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>sun_train_track_a_00924</td>\n",
       "      <td>lagu ieu ngawakili perasaan abdi aynaüò•</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "0    sun_train_track_a_00001   \n",
       "1    sun_train_track_a_00002   \n",
       "2    sun_train_track_a_00003   \n",
       "3    sun_train_track_a_00004   \n",
       "4    sun_train_track_a_00005   \n",
       "..                       ...   \n",
       "919  sun_train_track_a_00920   \n",
       "920  sun_train_track_a_00921   \n",
       "921  sun_train_track_a_00922   \n",
       "922  sun_train_track_a_00923   \n",
       "923  sun_train_track_a_00924   \n",
       "\n",
       "                                                  text  Anger  Disgust  Fear  \\\n",
       "0               mang dana ,uing can ngopi, kumaha ieu?      0        0     0   \n",
       "1    Siap teu nanaon nuhun pisan tos nonton,kumaha ...      0        0     0   \n",
       "2    ulin ka tasik mang, urang hayang asup kana kon...      0        0     0   \n",
       "3             Pokona bakalan sukses akang¬≤ ieu mah üëçüëçüëç      0        0     0   \n",
       "4    FIKSI mang dana kunn tara nyieun vidio deui ma...      0        0     0   \n",
       "..                                                 ...    ...      ...   ...   \n",
       "919     bener mang teu karasa nya waktu duh kmh sehat?      0        0     0   \n",
       "920  Terang ieu chenel ka akang willi ti stt wa rer...      0        0     0   \n",
       "921  Sabaraha gereget jadi orang sunda Kamari urang...      0        0     0   \n",
       "922  Yg nunggu vidio baru ngacung, ‚òù Naha jarang up...      0        0     0   \n",
       "923             lagu ieu ngawakili perasaan abdi aynaüò•      0        0     0   \n",
       "\n",
       "     Joy  Sadness  Surprise  \n",
       "0      1        0         0  \n",
       "1      1        0         0  \n",
       "2      1        0         0  \n",
       "3      1        0         0  \n",
       "4      0        0         0  \n",
       "..   ...      ...       ...  \n",
       "919    0        1         1  \n",
       "920    1        0         0  \n",
       "921    1        0         0  \n",
       "922    0        1         1  \n",
       "923    0        1         0  \n",
       "\n",
       "[924 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(raw_data_dir, f'train/track_a/{lang}.csv'))\n",
    "print(\"Training DF length:\", len(train_df))\n",
    "print()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>emotion</th>\n",
       "      <th>biasa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sun_train_track_a_00001</td>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sun_train_track_a_00002</td>\n",
       "      <td>Siap teu nanaon nuhun pisan tos nonton,kumaha ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sun_train_track_a_00003</td>\n",
       "      <td>ulin ka tasik mang, urang hayang asup kana kon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sun_train_track_a_00004</td>\n",
       "      <td>Pokona bakalan sukses akang¬≤ ieu mah üëçüëçüëç</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sun_train_track_a_00005</td>\n",
       "      <td>FIKSI mang dana kunn tara nyieun vidio deui ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>biasa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                               text  \\\n",
       "0  sun_train_track_a_00001             mang dana ,uing can ngopi, kumaha ieu?   \n",
       "1  sun_train_track_a_00002  Siap teu nanaon nuhun pisan tos nonton,kumaha ...   \n",
       "2  sun_train_track_a_00003  ulin ka tasik mang, urang hayang asup kana kon...   \n",
       "3  sun_train_track_a_00004           Pokona bakalan sukses akang¬≤ ieu mah üëçüëçüëç   \n",
       "4  sun_train_track_a_00005  FIKSI mang dana kunn tara nyieun vidio deui ma...   \n",
       "\n",
       "   marah  jijik  takut  senang  sedih  terkejut emotion  biasa  \n",
       "0      0      0      0       1      0         0  senang      0  \n",
       "1      0      0      0       1      0         0  senang      0  \n",
       "2      0      0      0       1      0         0  senang      0  \n",
       "3      0      0      0       1      0         0  senang      0  \n",
       "4      0      0      0       0      0         0   biasa      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_col_map = {\n",
    "    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n",
    "    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': '√ºberraschung' },\n",
    "    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "}\n",
    "emotion_cols = list(emotion_col_map[lang].values())\n",
    "\n",
    "neutral_emotion_map = {\n",
    "    'eng': 'neutral',\n",
    "    'deu': 'neutral',\n",
    "    'sun': 'biasa',\n",
    "}\n",
    "neutral_emotion = neutral_emotion_map[lang]\n",
    "\n",
    "# Rename emotion columns\n",
    "train_df = train_df.rename(columns=emotion_col_map[lang])\n",
    "\n",
    "# Create 'emotion' column by combining the positive emotions\n",
    "train_df['emotion'] = train_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "train_df['emotion'] = train_df['emotion'].replace('', neutral_emotion) # Fill neutral emotion\n",
    "\n",
    "# Create neutral emotion column\n",
    "train_df[neutral_emotion_map[lang]] = (train_df['emotion'] == neutral_emotion).astype(int)\n",
    "emotion_cols += [neutral_emotion]\n",
    "print(\"Emotion columns:\", emotion_cols)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length (splitted): 595 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Validation DF length: 128 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Testing DF length: 128 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    }
   ],
   "source": [
    "# Stratified split the data\n",
    "def create_stratify_col(df):\n",
    "    # Create 'stratify' column for stratified split\n",
    "    df['stratify'] = df['emotion']\n",
    "\n",
    "    # Identify classes with only one member\n",
    "    single_class = df['emotion'].value_counts()[df['emotion'].value_counts() == 1].index\n",
    "\n",
    "    # Assign a dummy value for the 'stratify' column for these classes\n",
    "    df.loc[df['emotion'].isin(single_class), 'stratify'] = 'dummy'\n",
    "\n",
    "create_stratify_col(train_df)\n",
    "\n",
    "emotion_lt_7 = train_df['emotion'].value_counts()[(train_df['emotion'].value_counts() < 7)].index.tolist()\n",
    "emotion_lt_7_cond = train_df['emotion'].isin(emotion_lt_7)\n",
    "train_df_emotion_lt_7 = train_df[emotion_lt_7_cond]\n",
    "train_df = train_df[~emotion_lt_7_cond]\n",
    "\n",
    "# Split training DF into training and validation DFs\n",
    "if len(split_sizes) == 3:\n",
    "    train_df_, val_test_df = train_test_split(train_df[['text', 'emotion'] + emotion_cols],\n",
    "                                        train_size=split_sizes[0],\n",
    "                                        stratify=train_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "    \n",
    "    create_stratify_col(val_test_df)\n",
    "    test_size = split_sizes[-1]/(split_sizes[1] + split_sizes[-1])\n",
    "    val_df, test_df = train_test_split(val_test_df[['text', 'emotion'] + emotion_cols],\n",
    "                                        test_size=test_size,\n",
    "                                        stratify=val_test_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "    \n",
    "    print(\"Training DF length (splitted):\", len(train_df_), \"-->\", train_df_.columns.tolist())\n",
    "    print(\"Validation DF length:\", len(val_df), \"-->\", val_df.columns.tolist())\n",
    "    print(\"Testing DF length:\", len(test_df), \"-->\", test_df.columns.tolist())\n",
    "\n",
    "train_df_ = pd.concat([train_df_, train_df_emotion_lt_7[['text', 'emotion'] + emotion_cols]])\n",
    "\n",
    "# dev_df = pd.read_csv(os.path.join(raw_data_dir, f'dev/track_a/{lang}_a.csv'))\n",
    "# dev_df = dev_df.rename(columns=emotion_col_map[lang])\n",
    "# dev_df['emotion'] = None\n",
    "# dev_df = dev_df[['text', 'emotion'] + emotion_cols]\n",
    "# print(\"Dev. DF length:\", len(dev_df), \"-->\", dev_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "senang                     66\n",
       "senang, terkejut           19\n",
       "sedih                      13\n",
       "senang, sedih               7\n",
       "biasa                       6\n",
       "terkejut                    3\n",
       "marah, jijik                2\n",
       "sedih, terkejut             2\n",
       "marah, sedih                2\n",
       "jijik, senang               2\n",
       "senang, sedih, terkejut     1\n",
       "marah, jijik, terkejut      1\n",
       "marah                       1\n",
       "takut, sedih                1\n",
       "takut, senang               1\n",
       "marah, sedih, terkejut      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/preprocessed_data/track_a/sun_70_15_15_stratify_v2\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "save_dir = os.path.join(preprocessed_data_dir, 'track_a', hf_data_config)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df_.to_csv(os.path.join(save_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'), index=False)\n",
    "# dev_df.to_csv(os.path.join(save_dir, 'dev.csv'), index=False)\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset/commit/7921baad1d35851e6b8dcfc877d9b838befdb0a0', commit_message='Upload folder using huggingface_hub', commit_description='', oid='7921baad1d35851e6b8dcfc877d9b838befdb0a0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=hf_data_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data/track_a', hf_data_config),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

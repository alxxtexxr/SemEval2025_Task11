{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face dataset config: sun_go_emotions_70_15_15_stratify_v2\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "# lang = 'eng'\n",
    "lang = 'sun_go_emotions'\n",
    "# raw_data_dir = './data/public_data/'\n",
    "raw_data_dir = './data/augmented_data/'\n",
    "preprocessed_data_dir = './data/preprocessed_data/'\n",
    "split_sizes = [0.7, 0.15, 0.15]\n",
    "assert sum(split_sizes) == 1.0\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = lang + '_' + '_'.join([str(int(split_size * 100)) for split_size in split_sizes]) + '_stratify_v2'\n",
    "print(\"Hugging Face dataset config:\", hf_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length: 2495\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aya randa ker nguseup Pantun sunda meuni reuseup</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastina ath mang ku abdi shere ken knu grup + SW</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mang Fiksi t√©h urang Majalengka og√©?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedih Mang Ai kudu D Caritakeun MahüòÑüôè</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>Nya, anjeun geus m√©akkeun dua jam.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>Kuring teu maca artikel anjeun tapi kuring nya...</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>Aya sababaraha variasi sapanjang taun.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Kuring mendakan sahanteuna hiji putri duyung u...</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>teu aya anu husus. eta beda-beda.</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2495 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        emotion  marah  \\\n",
       "0      Aya randa ker nguseup Pantun sunda meuni reuseup         senang      0   \n",
       "1      pastina ath mang ku abdi shere ken knu grup + SW          biasa      0   \n",
       "2                  Mang Fiksi t√©h urang Majalengka og√©?         senang      0   \n",
       "3                mang dana ,uing can ngopi, kumaha ieu?         senang      0   \n",
       "4                 Sedih Mang Ai kudu D Caritakeun MahüòÑüôè  senang, sedih      0   \n",
       "...                                                 ...            ...    ...   \n",
       "2490                 Nya, anjeun geus m√©akkeun dua jam.          biasa      0   \n",
       "2491  Kuring teu maca artikel anjeun tapi kuring nya...          biasa      0   \n",
       "2492             Aya sababaraha variasi sapanjang taun.          biasa      0   \n",
       "2493  Kuring mendakan sahanteuna hiji putri duyung u...          biasa      0   \n",
       "2494                  teu aya anu husus. eta beda-beda.          biasa      0   \n",
       "\n",
       "      jijik  takut  senang  sedih  terkejut  biasa  \n",
       "0         0      0       1      0         0      0  \n",
       "1         0      0       0      0         0      1  \n",
       "2         0      0       1      0         0      0  \n",
       "3         0      0       1      0         0      0  \n",
       "4         0      0       1      1         0      0  \n",
       "...     ...    ...     ...    ...       ...    ...  \n",
       "2490      0      0       0      0         0      1  \n",
       "2491      0      0       0      0         0      1  \n",
       "2492      0      0       0      0         0      1  \n",
       "2493      0      0       0      0         0      1  \n",
       "2494      0      0       0      0         0      1  \n",
       "\n",
       "[2495 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(raw_data_dir, f'train/track_a/{lang}.csv'))\n",
    "print(\"Training DF length:\", len(train_df))\n",
    "print()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion columns: ['marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>marah</th>\n",
       "      <th>jijik</th>\n",
       "      <th>takut</th>\n",
       "      <th>senang</th>\n",
       "      <th>sedih</th>\n",
       "      <th>terkejut</th>\n",
       "      <th>biasa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aya randa ker nguseup Pantun sunda meuni reuseup</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pastina ath mang ku abdi shere ken knu grup + SW</td>\n",
       "      <td>biasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mang Fiksi t√©h urang Majalengka og√©?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mang dana ,uing can ngopi, kumaha ieu?</td>\n",
       "      <td>senang</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedih Mang Ai kudu D Caritakeun MahüòÑüôè</td>\n",
       "      <td>senang, sedih</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text        emotion  marah  \\\n",
       "0  Aya randa ker nguseup Pantun sunda meuni reuseup         senang      0   \n",
       "1  pastina ath mang ku abdi shere ken knu grup + SW          biasa      0   \n",
       "2              Mang Fiksi t√©h urang Majalengka og√©?         senang      0   \n",
       "3            mang dana ,uing can ngopi, kumaha ieu?         senang      0   \n",
       "4             Sedih Mang Ai kudu D Caritakeun MahüòÑüôè  senang, sedih      0   \n",
       "\n",
       "   jijik  takut  senang  sedih  terkejut  biasa  \n",
       "0      0      0       1      0         0      0  \n",
       "1      0      0       0      0         0      1  \n",
       "2      0      0       1      0         0      0  \n",
       "3      0      0       1      0         0      0  \n",
       "4      0      0       1      1         0      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_col_map = {\n",
    "    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n",
    "    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': '√ºberraschung' },\n",
    "    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "    'sun_go_emotions': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "}\n",
    "emotion_cols = list(emotion_col_map[lang].values())\n",
    "\n",
    "neutral_emotion_map = {\n",
    "    'eng': 'neutral',\n",
    "    'deu': 'neutral',\n",
    "    'sun': 'biasa',\n",
    "    'sun_go_emotions': 'biasa',\n",
    "}\n",
    "neutral_emotion = neutral_emotion_map[lang]\n",
    "\n",
    "# Rename emotion columns\n",
    "train_df = train_df.rename(columns=emotion_col_map[lang])\n",
    "\n",
    "# Create 'emotion' column by combining the positive emotions\n",
    "train_df['emotion'] = train_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "train_df['emotion'] = train_df['emotion'].replace('', neutral_emotion) # Fill neutral emotion\n",
    "\n",
    "# Create neutral emotion column\n",
    "train_df[neutral_emotion_map[lang]] = (train_df['emotion'] == neutral_emotion).astype(int)\n",
    "emotion_cols += [neutral_emotion]\n",
    "print(\"Emotion columns:\", emotion_cols)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length (splitted): 1702 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Validation DF length: 365 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n",
      "Testing DF length: 365 --> ['text', 'emotion', 'marah', 'jijik', 'takut', 'senang', 'sedih', 'terkejut', 'biasa']\n"
     ]
    }
   ],
   "source": [
    "# Stratified split the data\n",
    "def create_stratify_col(df):\n",
    "    # Create 'stratify' column for stratified split\n",
    "    df['stratify'] = df['emotion']\n",
    "\n",
    "    # Identify classes with only one member\n",
    "    single_class = df['emotion'].value_counts()[df['emotion'].value_counts() == 1].index\n",
    "\n",
    "    # Assign a dummy value for the 'stratify' column for these classes\n",
    "    df.loc[df['emotion'].isin(single_class), 'stratify'] = 'dummy'\n",
    "\n",
    "create_stratify_col(train_df)\n",
    "\n",
    "emotion_lt_7 = train_df['emotion'].value_counts()[(train_df['emotion'].value_counts() < 7)].index.tolist()\n",
    "emotion_lt_7_cond = train_df['emotion'].isin(emotion_lt_7)\n",
    "train_df_emotion_lt_7 = train_df[emotion_lt_7_cond]\n",
    "train_df = train_df[~emotion_lt_7_cond]\n",
    "\n",
    "# Split training DF into training and validation DFs\n",
    "if len(split_sizes) == 3:\n",
    "    train_df_, val_test_df = train_test_split(train_df[['text', 'emotion'] + emotion_cols],\n",
    "                                              train_size=split_sizes[0],\n",
    "                                              stratify=train_df['stratify'],\n",
    "                                              random_state=seed)\n",
    "    \n",
    "    create_stratify_col(val_test_df)\n",
    "    test_size = split_sizes[-1]/(split_sizes[1] + split_sizes[-1])\n",
    "    val_df, test_df = train_test_split(val_test_df[['text', 'emotion'] + emotion_cols],\n",
    "                                        test_size=test_size,\n",
    "                                        stratify=val_test_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "    \n",
    "    print(\"Training DF length (splitted):\", len(train_df_), \"-->\", train_df_.columns.tolist())\n",
    "    print(\"Validation DF length:\", len(val_df), \"-->\", val_df.columns.tolist())\n",
    "    print(\"Testing DF length:\", len(test_df), \"-->\", test_df.columns.tolist())\n",
    "\n",
    "train_df_ = pd.concat([train_df_, train_df_emotion_lt_7[['text', 'emotion'] + emotion_cols]])\n",
    "\n",
    "# dev_df = pd.read_csv(os.path.join(raw_data_dir, f'dev/track_a/{lang}_a.csv'))\n",
    "# dev_df = dev_df.rename(columns=emotion_col_map[lang])\n",
    "# dev_df['emotion'] = None\n",
    "# dev_df = dev_df[['text', 'emotion'] + emotion_cols]\n",
    "# print(\"Dev. DF length:\", len(dev_df), \"-->\", dev_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "senang                     65\n",
       "sedih                      40\n",
       "terkejut                   38\n",
       "biasa                      38\n",
       "takut                      37\n",
       "marah                      37\n",
       "jijik                      33\n",
       "senang, terkejut           20\n",
       "marah, jijik               14\n",
       "senang, sedih               7\n",
       "takut, sedih                6\n",
       "marah, sedih                4\n",
       "jijik, takut                3\n",
       "jijik, sedih                3\n",
       "sedih, terkejut             3\n",
       "jijik, terkejut             2\n",
       "takut, terkejut             2\n",
       "senang, sedih, terkejut     2\n",
       "marah, terkejut             2\n",
       "jijik, senang               2\n",
       "marah, takut                2\n",
       "marah, jijik, terkejut      2\n",
       "marah, sedih, terkejut      1\n",
       "takut, senang, terkejut     1\n",
       "takut, senang               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/preprocessed_data/track_a/sun_go_emotions_70_15_15_stratify_v2\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(preprocessed_data_dir, 'track_a', hf_data_config)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df_.to_csv(os.path.join(save_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'), index=False)\n",
    "# dev_df.to_csv(os.path.join(save_dir, 'dev.csv'), index=False)\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset/commit/960dfef1e5e565e1b4debdfb7fc4c550996cef54', commit_message='Upload folder using huggingface_hub', commit_description='', oid='960dfef1e5e565e1b4debdfb7fc4c550996cef54', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='alxxtexxr/SemEval2025-Task11-Dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=hf_data_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data/track_a', hf_data_config),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

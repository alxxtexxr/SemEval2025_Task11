{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "data_dir = './data/sundanese_twitter_dataset'\n",
    "preprocessed_data_dir = './data/sundanese_twitter_dataset/processed_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P $data_dir https://raw.githubusercontent.com/virgantara/sundanese-twitter-dataset/refs/heads/master/sundanese.csv\n",
    "# !wget -P $data_dir https://raw.githubusercontent.com/virgantara/sundanese-twitter-dataset/refs/heads/master/newdataset.csv\n",
    "# !wget -P $data_dir https://raw.githubusercontent.com/virgantara/sundanese-twitter-dataset/refs/heads/master/newone.csv\n",
    "# !wget -P $data_dir https://raw.githubusercontent.com/virgantara/sundanese-twitter-dataset/refs/heads/master/testdataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of newone_df: 2518\n",
      "Length of testdataset_df: 12\n",
      "\n",
      "newone_df Columns: ['label', 'data']\n",
      "testdataset_df Columns: ['label', 'data']\n",
      "\n",
      "newone_df labels: [2 1 4 3]\n",
      "testdataset_df labels: ['marah' 'takut' 'sedih' 'senang']\n"
     ]
    }
   ],
   "source": [
    "# newdataset_df = pd.read_csv(os.path.join(data_dir, 'newdataset.csv'))\n",
    "newone_df = pd.read_csv(os.path.join(data_dir, 'newone.csv'))\n",
    "# sundanese_df = pd.read_csv(os.path.join(data_dir, 'sundanese.csv'))\n",
    "testdataset_df = pd.read_csv(os.path.join(data_dir, 'testdataset.csv'))\n",
    "\n",
    "# print(\"Length of newdataset_df:\", len(newdataset_df))\n",
    "print(\"Length of newone_df:\", len(newone_df))\n",
    "# print(\"Length of sundanese_df:\", len(sundanese_df))\n",
    "print(\"Length of testdataset_df:\", len(testdataset_df))\n",
    "print()\n",
    "# print(\"newdataset_df Columns:\", list(newdataset_df.columns))\n",
    "print(\"newone_df Columns:\", list(newone_df.columns))\n",
    "# print(\"sundanese_df Columns:\", list(sundanese_df.columns))\n",
    "print(\"testdataset_df Columns:\", list(testdataset_df.columns))\n",
    "print()\n",
    "\n",
    "print(\"newone_df labels:\", newone_df['label'].unique())\n",
    "print(\"testdataset_df labels:\", testdataset_df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>...nepi ayeuna mun inget indung kadang sok cir...</td>\n",
       "      <td>sedih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Hidup aing, kumaha aing\" Kalo hidup maneh nyi...</td>\n",
       "      <td>marah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Insidious1 aja, udah bikin muringkak. Komo In...</td>\n",
       "      <td>takut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Kami fokeus di AFC..hahahahaha..\" ngeunah seu...</td>\n",
       "      <td>senang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Mah potoin iin ih sama jurig itu\" bari jeung ...</td>\n",
       "      <td>takut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               data emotion\n",
       "0      1  ...nepi ayeuna mun inget indung kadang sok cir...   sedih\n",
       "1      0  \"Hidup aing, kumaha aing\" Kalo hidup maneh nyi...   marah\n",
       "2      3  \"Insidious1 aja, udah bikin muringkak. Komo In...   takut\n",
       "3      2  \"Kami fokeus di AFC..hahahahaha..\" ngeunah seu...  senang\n",
       "4      3  \"Mah potoin iin ih sama jurig itu\" bari jeung ...   takut"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion2label = {\n",
    "    'marah': 0,\n",
    "    'sedih': 1,\n",
    "    'senang': 2,\n",
    "    'takut': 3,\n",
    "}\n",
    "\n",
    "train_val_df = newone_df.copy()\n",
    "train_val_df['emotion'] = train_val_df['label'].map({\n",
    "    1: 'marah',\n",
    "    2: 'sedih',\n",
    "    3: 'senang',\n",
    "    4: 'takut',\n",
    "})\n",
    "train_val_df['label'] = train_val_df['emotion'].map(emotion2label)\n",
    "train_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marah</td>\n",
       "      <td>Kade kabentar ah, lagi males marah2. Modar we ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marah</td>\n",
       "      <td>jadi lieur anjing hayang modar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marah</td>\n",
       "      <td>Mamanas wae sia mah anjing, gera modar sia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>takut</td>\n",
       "      <td>Punten ini akurat ga ya sieun ihh daerah aku m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>takut</td>\n",
       "      <td>Teu hayang, sieun geus gede dikerekeb.... moda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion                                               data  label\n",
       "0   marah  Kade kabentar ah, lagi males marah2. Modar we ...      0\n",
       "1   marah                     jadi lieur anjing hayang modar      0\n",
       "2   marah         Mamanas wae sia mah anjing, gera modar sia      0\n",
       "3   takut  Punten ini akurat ga ya sieun ihh daerah aku m...      3\n",
       "4   takut  Teu hayang, sieun geus gede dikerekeb.... moda...      3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testdataset_df.rename(columns={'label': 'emotion'})\n",
    "test_df['label'] = test_df['emotion'].map(emotion2label)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing split size: 12\n",
      "Validation split size: 12\n",
      "Training split size: 2506\n"
     ]
    }
   ],
   "source": [
    "test_size = len(test_df)\n",
    "val_size = test_size\n",
    "train_size = len(train_val_df) - val_size\n",
    "\n",
    "print(\"Testing split size:\", test_size)\n",
    "print(\"Validation split size:\", val_size)\n",
    "print(\"Training split size:\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_df: 2506\n",
      "Length of val_df: 12\n",
      "Length of test_df: 12\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(train_val_df,\n",
    "                                    train_size=train_size,\n",
    "                                    stratify=train_val_df['label'],\n",
    "                                    random_state=seed)\n",
    "\n",
    "print(\"Length of train_df:\", len(train_df))\n",
    "print(\"Length of val_df:\", len(val_df))\n",
    "print(\"Length of test_df:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face data ID: alxxtexxr/sundanese-twitter-dataset\n",
      "Hugging Face data config: 2506_12_12\n"
     ]
    }
   ],
   "source": [
    "hf_data_id = 'alxxtexxr/sundanese-twitter-dataset'\n",
    "hf_data_config = f'{train_size}_{val_size}_{test_size}'\n",
    "print(\"Hugging Face data ID:\", hf_data_id)\n",
    "print(\"Hugging Face data config:\", hf_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/sundanese_twitter_dataset/processed_data/2506_12_12\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(preprocessed_data_dir, hf_data_config)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df.to_csv(os.path.join(save_dir, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'), index=False)\n",
    "# dev_df.to_csv(os.path.join(save_dir, 'dev.csv'), index=False)\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/sundanese-twitter-dataset/commit/790d99d62e058768c35afa532aec95fb6a67f70a', commit_message='Upload folder using huggingface_hub', commit_description='', oid='790d99d62e058768c35afa532aec95fb6a67f70a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=hf_data_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data', hf_data_config),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

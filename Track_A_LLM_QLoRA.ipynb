{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- Finetune Llama 3 for Sentiment Analysis (https://www.kaggle.com/code/lucamassaron/fine-tune-llama-3-for-sentiment-analysis)\n",
    "- Finetune Llama 2 for Sentiment Analysis (https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 24 12:24:06 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0             25W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "# %pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "%pip install -q -U bitsandbytes\n",
    "%pip install -q -U transformers\n",
    "%pip install -q -U accelerate\n",
    "%pip install -q -U datasets\n",
    "%pip install -q -U trl\n",
    "%pip install -q -U peft\n",
    "# %pip install -q -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes as bnb\n",
    "import wandb\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = 'eng'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # Might not work on Kaggle\n",
    "model_id = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "project_name = 'Llama-3.2-1B-Instruct-Emotion-eng'\n",
    "hub_model_id = f'alxxtexxr/{project_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling two features in PyTorch related to memory efficiency and speed during operations on the Graphics Processing Unit (GPU) specifically for the scaled dot product attention (SDPA) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set random seed for Torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic algorithms\n",
    "\n",
    "    # Set random seed for Transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face token (https://huggingface.co/settings/tokens):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# print(\"Hugging Face token (https://huggingface.co/settings/tokens):\")\n",
    "# if not os.path.exists('/root/.cache/huggingface/token'):\n",
    "#     hf_token = input()\n",
    "#     !huggingface-cli login --token $hf_token\n",
    "# else:\n",
    "#     print(\"Hugging Face token has already been saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=alimtegar\n",
      "env: WANDB_PROJECT=Llama-3.2-1B-Instruct-Emotion-eng\n"
     ]
    }
   ],
   "source": [
    "#  Login with your authentication key\n",
    "wandb.login()\n",
    "\n",
    "# setup wandb environment variables\n",
    "%env WANDB_ENTITY=alimtegar\n",
    "%env WANDB_PROJECT=Llama-3.2-1B-Instruct-Emotion-eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9ac55fd04841758a2ef017ed50b3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessed_data/train/eng.csv:   0%|          | 0.00/236k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93a2bd50a7d47378965c238c80b547c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessed_data/val/eng.csv:   0%|          | 0.00/57.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aae83ab0d249fda7d4b89dd5e43904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessed_data/test/eng.csv:   0%|          | 0.00/9.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703c3c49490c45a9bc7a076c37c12b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecbd73436224f5e9e794a972c069934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bdba2c06454a81824ccbd7ac87e556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF columns: ['Unnamed: 0', 'text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "Emotions columns: ['anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "\n",
      "Train DF size: 2214\n",
      "Validation DF size: 554\n",
      "Testing DF size: 116\n"
     ]
    }
   ],
   "source": [
    "data_files = {\n",
    "    'train': f'preprocessed_data/train/{lang}.csv', \n",
    "    'val': f'preprocessed_data/val/{lang}.csv',\n",
    "    'test': f'preprocessed_data/test/{lang}.csv',\n",
    "}\n",
    "dataset = load_dataset('alxxtexxr/SemEval2025-Task11-Dataset', data_files=data_files)\n",
    "\n",
    "splits = data_files.keys()\n",
    "df = {split: pd.DataFrame(dataset[split]) for split in splits}\n",
    "\n",
    "cols = list(df['train'].columns)\n",
    "print(\"DF columns:\", cols)\n",
    "\n",
    "emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion']]\n",
    "# neutral_emotion = df['train'][df['train'][emotion_cols].sum(axis=1) == 0]['emotion'].iloc[0]\n",
    "# emotions = emotion_cols + [neutral_emotion]\n",
    "print(\"Emotions columns:\", emotion_cols)\n",
    "print()\n",
    "\n",
    "print(\"Train DF size:\", len(df['train']))\n",
    "print(\"Validation DF size:\", len(df['val']))\n",
    "print(\"Testing DF size:\", len(df['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create One-Hot Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['train']['one_hot_emotion'] = df['train'].apply(lambda row: row[emotion_cols].tolist(), axis=1).tolist()\n",
    "# df['val']['one_hot_emotion'] = df['val'].apply(lambda row: row[emotion_cols].tolist(), axis=1).tolist()\n",
    "\n",
    "# df['val']['one_hot_emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prompt Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train prompts:\n",
      "\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: I now have 12 of those canker sore suckers in my mouth along with a fever since friday.\n",
      "\n",
      "### Output\n",
      "Emotion(s): fear, sad\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: It just... went away.\n",
      "\n",
      "### Output\n",
      "Emotion(s): fear, sad, surprise\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: I naively walked up and stuck my head in the driver's window hole.\n",
      "\n",
      "### Output\n",
      "Emotion(s): fear, surprise\n",
      "================================================================================================================================================================================================\n",
      "\n",
      "Testing prompts:\n",
      "\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: My mouth fell open `` No, no, no... I..\n",
      "\n",
      "### Output\n",
      "Emotion(s):\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: You can barely make out your daughter's pale form in the darkness of your room.\n",
      "\n",
      "### Output\n",
      "Emotion(s):\n",
      "================================================================================================================================================================================================\n",
      "### Instruction\n",
      "Detect the emotion(s) in the given input text. \n",
      "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
      "\n",
      "### Input\n",
      "Text: But after blinking my eyes for a few times lepas tu tampar-tampar muka sikit, memang sah la yang penghantar itu Hanis Zalikha.\n",
      "\n",
      "### Output\n",
      "Emotion(s):\n",
      "================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"### Instruction\n",
    "Detect the emotion(s) in the given input text. \n",
    "The detected emotion(s) can be one or a combination of the following: anger, fear, joy, sad, surprise, or neutral\n",
    "\n",
    "### Input\n",
    "Text: {text}\n",
    "\n",
    "### Output\n",
    "Emotion(s): {emotion}\"\"\"\n",
    "\n",
    "def create_prompt(row):\n",
    "    emotion_list = row['emotion'].replace(\" \", \"\").split(\",\")\n",
    "    emotion = \", \".join([f\"{e}\" for e in row['emotion'].replace(\" \", \"\").split(\",\")])#[1:]#+ \"]\"\n",
    "    # emotion = '\\n'.join([f\"- {e}\" for e in emotion_list])[2:]\n",
    "    return prompt_template.format(text=row['text'], emotion=emotion).strip()\n",
    "\n",
    "def create_test_prompt(row):\n",
    "    return prompt_template.format(text=row['text'], emotion=\"\").strip()\n",
    "\n",
    "df['train']['prompt'] = df['train'].apply(create_prompt, axis=1)\n",
    "df['val']['prompt'] = df['val'].apply(create_test_prompt, axis=1)\n",
    "df['test']['prompt'] = df['test'].apply(create_test_prompt, axis=1)\n",
    "\n",
    "print(\"Train prompts:\\n\")\n",
    "for prompt in df['train']['prompt'].head(3):\n",
    "    print(prompt)\n",
    "    print(\"================================================================================================================================================================================================\")\n",
    "print()\n",
    "print(\"Testing prompts:\\n\")\n",
    "for prompt in df['test']['prompt'].head(3):\n",
    "    print(prompt)\n",
    "    print(\"================================================================================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train max. prompt length: 673\n",
      "Validation max. prompt length: 586\n",
      "Testing max. prompt length: 527\n",
      "\n",
      "Max. prompt length: 673 (<class 'int'>)\n"
     ]
    }
   ],
   "source": [
    "max_seq_lengths = {split: df[split]['prompt'].str.len().max() for split in splits}\n",
    "max_seq_length = int(max(max_seq_lengths.values()))\n",
    "\n",
    "print(\"Train max. prompt length:\", max_seq_lengths['train'])\n",
    "print(\"Validation max. prompt length:\", max_seq_lengths['val'])\n",
    "print(\"Testing max. prompt length:\", max_seq_lengths['test'])\n",
    "print()\n",
    "print(\"Max. prompt length:\", max_seq_length, f\"({type(max_seq_length)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['prompt'],\n",
       "     num_rows: 2214\n",
       " }),\n",
       " 'val': Dataset({\n",
       "     features: ['prompt'],\n",
       "     num_rows: 554\n",
       " })}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {split: Dataset.from_pandas(df[split][['prompt']]) for split in ['train', 'val']}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d19e926ce2847d8bd005399d23488e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b889d3dc711436ab1c5b271e7d80c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85873206a26d4e7fa0170cfa36886ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_dtype = torch.float16\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb57fba4b9b442a2b00623bbaa399514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f34428826574c4ba58d250a55afc5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c9410b4bf248dbb47b6ce468cea691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, max_seq_length=max_seq_length)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_new_tokens = df['train'].apply(lambda row: len(tokenizer.encode(row['emotion'])), axis=1).max()\n",
    "# print(\"Max. emotion tokens:\", max_new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation without Finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Y (554):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 1, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 0, 0, 1, 1],\n",
       " [0, 0, 0, 1, 0],\n",
       " [1, 1, 0, 0, 1],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0],\n",
       " [0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = df['val'].apply(lambda row: row[emotion_cols].tolist(), axis=1).tolist()\n",
    "print(f\"True Y ({len(y_true)}):\")\n",
    "y_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y (554):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 1, 0, 0],\n",
       " [0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 1, 0],\n",
       " [0, 0, 1, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode_emotion(emotion, emotion_cols):\n",
    "    emotions = emotion.replace(\" \", \"\").split(\",\")\n",
    "    one_hot_emotion = [1 if emotion_col in emotions else 0 for emotion_col in emotion_cols]\n",
    "    return one_hot_emotion\n",
    "\n",
    "def predict(df_, model, tokenizer, max_new_tokens=32, batch_size=128):\n",
    "    prompt = df_['prompt'].tolist()\n",
    "    pipe = pipeline(\n",
    "        task='text-generation',\n",
    "        model=model, \n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.001,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    outputs = pipe(prompt)\n",
    "    pred_emotion_list = [output[0]['generated_text'].split(\"Emotion(s): \")[-1].split(\"\\n\")[0].lower() for output in outputs]\n",
    "    y_pred = [one_hot_encode_emotion(pred_emotion_i, emotion_cols) for pred_emotion_i in pred_emotion_list]\n",
    "    return y_pred\n",
    "\n",
    "y_pred = predict(df['val'], model, tokenizer)\n",
    "print(f\"Predicted Y ({len(y_pred)}):\")\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro-Average): 0.49611398963730574\n",
      "F1 Score (Macro-Average): 0.4986404737915498\n",
      "\n",
      "F1 Score for 'anger': 0.5524861878453039\n",
      "F1 Score for 'fear': 0.5146443514644352\n",
      "F1 Score for 'joy': 0.5403508771929825\n",
      "F1 Score for 'sad': 0.5847176079734219\n",
      "F1 Score for 'surprise': 0.30100334448160543\n"
     ]
    }
   ],
   "source": [
    "# Compute F1 score for each type of averaging method\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0.0)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n",
    "# f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0.0)\n",
    "# f1_samples = f1_score(y_true, y_pred, average='samples', zero_division=0.0)\n",
    "f1_per_label = f1_score(y_true, y_pred, average=None, zero_division=0.0)\n",
    "\n",
    "\n",
    "print(f'F1 Score (Micro-Average): {f1_micro}')\n",
    "print(f'F1 Score (Macro-Average): {f1_macro}')\n",
    "print()\n",
    "for label, f1 in zip(emotion_cols, f1_per_label):\n",
    "    print(f\"F1 Score for '{label}': {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target LoRA modules: ['up_proj', 'o_proj', 'q_proj', 'k_proj', 'gate_proj', 'v_proj', 'down_proj']\n"
     ]
    }
   ],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names: # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "target_modules = find_all_linear_names(model)\n",
    "print(\"Target LoRA modules:\", target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:327: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf8e51d964f488c8a72b73817433b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:401: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.0,\n",
    "    r=64,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM',\n",
    "    target_modules=target_modules,\n",
    ")\n",
    "\n",
    "resume_from_checkpoint = 'checkpoint-830'\n",
    "resume_from_lr = 3.187593272453288e-05\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "    num_train_epochs=5,            # number of training epochs\n",
    "    per_device_train_batch_size=1, # batch size per device during training\n",
    "    gradient_accumulation_steps=8, # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,   # use gradient checkpointing to save memory\n",
    "    optim='paged_adamw_32bit',\n",
    "    # save_steps=0,\n",
    "    logging_steps=20,                         \n",
    "    learning_rate=2e-4 if not resume_from_lr else resume_from_lr, # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,             # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03 if not resume_from_checkpoint else 0.0, # warmup ratio based on QLoRA paper\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type='cosine',    # use cosine learning rate scheduler\n",
    "    report_to='wandb',             # report metrics to w&b\n",
    "    # eval_strategy=\"steps\",       # save checkpoint every epoch\n",
    "    # eval_steps = 20.\n",
    "\n",
    "    # Arguments for saving the training\n",
    "    output_dir=project_name,       # directory to save and repository id\n",
    "    save_strategy='epoch',         # save at each epoch\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=hub_model_id,\n",
    "    hub_strategy='all_checkpoints',\n",
    "\n",
    "    # Arguments for resuming the training\n",
    "    resume_from_checkpoint=resume_from_checkpoint\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    # eval_dataset==datasets['val'],\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field='prompt',\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        'add_special_tokens': False,\n",
    "        'append_concat_token': False,\n",
    "    },\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d0193948314e12bd717bce90fb6256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113777666668687, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241024_123045-vxnzrnev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alimtegar/Llama-3.2-1B-Instruct-Emotion-eng/runs/vxnzrnev' target=\"_blank\">Llama-3.2-1B-Instruct-Emotion-eng</a></strong> to <a href='https://wandb.ai/alimtegar/Llama-3.2-1B-Instruct-Emotion-eng' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alimtegar/Llama-3.2-1B-Instruct-Emotion-eng' target=\"_blank\">https://wandb.ai/alimtegar/Llama-3.2-1B-Instruct-Emotion-eng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alimtegar/Llama-3.2-1B-Instruct-Emotion-eng/runs/vxnzrnev' target=\"_blank\">https://wandb.ai/alimtegar/Llama-3.2-1B-Instruct-Emotion-eng/runs/vxnzrnev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1380' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1380/1380 50:32, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.970100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.878800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.896100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.890600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.879900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.919800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.903400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.864900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.873500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.778400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.860900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.884100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.893900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.889700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.827400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.820100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.802500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.915200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.870400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.860100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.843600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.805100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.802200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.814400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1380, training_loss=0.8942732499993366, metrics={'train_runtime': 3038.7168, 'train_samples_per_second': 3.643, 'train_steps_per_second': 0.454, 'total_flos': 5118029326725120.0, 'train_loss': 0.8942732499993366, 'epoch': 4.9864498644986455})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation After Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y (FT) (554):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 1, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 1, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 1, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [0, 1, 0, 1, 1],\n",
       " [1, 1, 0, 1, 1],\n",
       " [1, 1, 0, 1, 1],\n",
       " [1, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = True\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "y_pred_ft = predict(df['val'], model, tokenizer, batch_size=64)\n",
    "print(f\"Predicted Y (FT) ({len(y_pred_ft)}):\")\n",
    "y_pred_ft[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro-Average): 0.6013719512195123\n",
      "F1 Score (Macro-Average): 0.6124657330409786\n",
      "\n",
      "F1 Score for 'anger': 0.638888888888889\n",
      "F1 Score for 'fear': 0.8198074277854195\n",
      "F1 Score for 'joy': 0.6586102719033232\n",
      "F1 Score for 'sad': 0.48739495798319327\n",
      "F1 Score for 'surprise': 0.45762711864406774\n"
     ]
    }
   ],
   "source": [
    "# Compute F1 score for each type of averaging method\n",
    "f1_micro = f1_score(y_true, y_pred_ft, average='micro', zero_division=0.0)\n",
    "f1_macro = f1_score(y_true, y_pred_ft, average='macro', zero_division=0.0)\n",
    "# f1_weighted = f1_score(y_true, y_pred_ft, average='weighted', zero_division=0.0)\n",
    "# f1_samples = f1_score(y_true, y_pred_ft, average='samples', zero_division=0.0)\n",
    "f1_per_label = f1_score(y_true, y_pred_ft, average=None, zero_division=0.0)\n",
    "\n",
    "\n",
    "print(f'F1 Score (Micro-Average): {f1_micro}')\n",
    "print(f'F1 Score (Macro-Average): {f1_macro}')\n",
    "print()\n",
    "for label, f1 in zip(emotion_cols, f1_per_label):\n",
    "    print(f\"F1 Score for '{label}': {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

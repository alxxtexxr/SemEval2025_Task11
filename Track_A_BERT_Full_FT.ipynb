{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- Multi-Label Classification Model From Scratch: Step-by-Step Tutorial (https://huggingface.co/blog/Valerii-Knowledgator/multi-label-classification)\n",
    "- https://github.com/NielsRogge/Transformers-Tutorials/blob/master/BERT/Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\n",
    "- https://github.com/huggingface/notebooks/blob/main/examples/text_classification.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U datasets transformers accelerate sentencepiece # evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "# import evaluate\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = 'eng'\n",
    "hf_model_id = 'google-bert/bert-base-uncased'\n",
    "# hf_model_id = 'google-bert/bert-large-uncased'\n",
    "hf_data_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "hf_data_config = 'track_a_eng_70_15_15'\n",
    "project_name = f'BERT-Base-SE2025T11A-{lang}-v0.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set random seed for Torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True  # Ensures deterministic results\n",
    "    torch.backends.cudnn.benchmark = False  # Avoids non-deterministic algorithms\n",
    "\n",
    "    # Set random seed for Transformers\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:99: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1f72c589164c6594051b4ed1cf91d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ssed_data/track_a/eng_70_15_15/train.csv:   0%|          | 0.00/199k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5bea3f9f9b4f139b5ff1679215d016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)cessed_data/track_a/eng_70_15_15/val.csv:   0%|          | 0.00/40.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc22506d4c64f78b384083cca0668d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)essed_data/track_a/eng_70_15_15/test.csv:   0%|          | 0.00/41.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a72e8ff2c84450e806233e99b9cfadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698568921fcd4763900759cb29d56059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e772f4bc85492a87a208eb596d2939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data columns: ['text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "Emotions columns: ['anger', 'fear', 'joy', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(hf_data_id, hf_data_config)\n",
    "\n",
    "cols = list(datasets['train'].features)\n",
    "emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion']]\n",
    "\n",
    "# splits = data_files.keys()\n",
    "# df = {split: pd.DataFrame(datasets[split]) for split in splits}\n",
    "\n",
    "# cols = list(df['train'].columns)\n",
    "print(\"Data columns:\", cols)\n",
    "\n",
    "# emotion_cols = [col for col in cols if col not in ['Unnamed: 0', 'text', 'emotion']]\n",
    "# # neutral_emotion = df['train'][df['train'][emotion_cols].sum(axis=1) == 0]['emotion'].iloc[0]\n",
    "# # emotions = emotion_cols + [neutral_emotion]\n",
    "print(\"Emotions columns:\", emotion_cols)\n",
    "# print()\n",
    "\n",
    "# print(\"Train DF size:\", len(df['train']))\n",
    "# print(\"Validation DF size:\", len(df['val']))\n",
    "# print(\"Testing DF size:\", len(df['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to ID:\n",
      "\n",
      "{'anger': 0,\n",
      " 'fear': 1,\n",
      " 'joy': 2,\n",
      " 'sad': 3,\n",
      " 'surprise': 4}\n",
      "\n",
      "ID to Class:\n",
      "\n",
      "{0: 'anger',\n",
      " 1: 'fear',\n",
      " 2: 'joy',\n",
      " 3: 'sad',\n",
      " 4: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "class2id = {class_:id for id, class_ in enumerate(emotion_cols)}\n",
    "id2class = {id:class_ for class_, id in class2id.items()}\n",
    "\n",
    "print(\"Class to ID:\\n\")\n",
    "pprint(class2id, width=1)\n",
    "print()\n",
    "print(\"ID to Class:\\n\")\n",
    "pprint(id2class, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454e8dcb83234889a5e7e39786f26d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1937 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7113ffb093064a6fa12fe2779b3c4bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot_encode_emotion(emotion, emotion_cols):\n",
    "    emotions = emotion.replace(\" \", \"\").split(\",\")\n",
    "    one_hot_emotion = [1.0 if emotion_col in emotions else 0.0 for emotion_col in emotion_cols] # Ensure that the label is float, not int\n",
    "    return one_hot_emotion\n",
    "\n",
    "def preprocess_function(data):\n",
    "   text = data['text']\n",
    "   emotion = data['emotion']\n",
    "   labels = one_hot_encode_emotion(emotion, emotion_cols)\n",
    "   data = tokenizer(text, truncation=True)\n",
    "   data['labels'] = labels\n",
    "   return data\n",
    "\n",
    "tokenized_datasets = {split: datasets[split].map(preprocess_function) for split in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: My knuckles growing whiter and whiter, my mind screaming at me that we should be out of here, we should almost be home.\n",
      "Emotion(s): anger, fear\n",
      "Labels: [1.0, 1.0, 0.0, 0.0, 0.0] --> ['anger', 'fear', 'joy', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "data = tokenized_datasets['train'][0]\n",
    "\n",
    "print(\"Text:\", data['text'])\n",
    "print(\"Emotion(s):\", data['emotion'])\n",
    "print(\"Labels:\", data['labels'], '-->', emotion_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    hf_model_id, \n",
    "    num_labels=len(emotion_cols),\n",
    "    id2label=id2class, label2id=class2id,\n",
    "    problem_type = \"multi_label_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "   return 1/(1 + np.exp(-x))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    probs = sigmoid(predictions)\n",
    "    y_pred = (probs > 0.5).astype(int)\n",
    "    y_true = labels.astype(int)\n",
    "\n",
    "    # Compute F1 score for each type of averaging method\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0.0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0.0)\n",
    "    # f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0.0)\n",
    "    # f1_samples = f1_score(y_true, y_pred, average='samples', zero_division=0.0)\n",
    "    f1_labels = f1_score(y_true, y_pred, average=None, zero_division=0.0)\n",
    "    f1_labels_dict = {f'f1_label_{emotion_cols[i]}': f1_labels[i] for i in range(len(f1_labels))}\n",
    "\n",
    "    return {\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        **f1_labels_dict,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-d7f5c93b8dd2>:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    # Training config\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # Logging config for training\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=50,\n",
    "\n",
    "    # Evaluation config during training\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=50,\n",
    "\n",
    "    # Model saving config\n",
    "    output_dir=project_name,\n",
    "    save_strategy='epoch',\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malimtegar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241027_150523-ly4smpox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/alimtegar/huggingface/runs/ly4smpox' target=\"_blank\">BERT-Base-SE2025T11A-eng-v0.4</a></strong> to <a href='https://wandb.ai/alimtegar/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/alimtegar/huggingface' target=\"_blank\">https://wandb.ai/alimtegar/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/alimtegar/huggingface/runs/ly4smpox' target=\"_blank\">https://wandb.ai/alimtegar/huggingface/runs/ly4smpox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='551' max='1938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 551/1938 01:04 < 02:42, 8.55 it/s, Epoch 0.57/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Label Anger</th>\n",
       "      <th>F1 Label Fear</th>\n",
       "      <th>F1 Label Joy</th>\n",
       "      <th>F1 Label Sad</th>\n",
       "      <th>F1 Label Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.591197</td>\n",
       "      <td>0.454034</td>\n",
       "      <td>0.147336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.581300</td>\n",
       "      <td>0.561901</td>\n",
       "      <td>0.454034</td>\n",
       "      <td>0.147336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.557033</td>\n",
       "      <td>0.454034</td>\n",
       "      <td>0.147336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.552300</td>\n",
       "      <td>0.548003</td>\n",
       "      <td>0.552672</td>\n",
       "      <td>0.273653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.486080</td>\n",
       "      <td>0.496425</td>\n",
       "      <td>0.255696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.774319</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.448087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>0.502605</td>\n",
       "      <td>0.592534</td>\n",
       "      <td>0.354802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771200</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.660494</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.450273</td>\n",
       "      <td>0.572534</td>\n",
       "      <td>0.404495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.416185</td>\n",
       "      <td>0.331210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.437290</td>\n",
       "      <td>0.646696</td>\n",
       "      <td>0.499726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.793037</td>\n",
       "      <td>0.562092</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.423117</td>\n",
       "      <td>0.659189</td>\n",
       "      <td>0.510148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.572770</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.405441</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.553158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820611</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.672489</td>\n",
       "      <td>0.621005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='193' max='208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [193/208 00:01 < 00:00, 99.59 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.37046584486961365,\n",
       " 'eval_f1_micro': 0.7386634844868735,\n",
       " 'eval_f1_macro': 0.6946360926564015,\n",
       " 'eval_f1_label_anger': 0.5688073394495413,\n",
       " 'eval_f1_label_fear': 0.8199121522693997,\n",
       " 'eval_f1_label_joy': 0.675,\n",
       " 'eval_f1_label_sad': 0.6855345911949685,\n",
       " 'eval_f1_label_surprise': 0.7239263803680982,\n",
       " 'eval_runtime': 3.2855,\n",
       " 'eval_samples_per_second': 168.62,\n",
       " 'eval_steps_per_second': 84.31,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: He ran outside with it to find this man at the bottom of our driveway.\n",
      "True emotion(s): fear, surprise\n",
      "Predicted emotion(s): fear, surprise\n"
     ]
    }
   ],
   "source": [
    "data = datasets['val'][1]\n",
    "text = data['text']\n",
    "emotion_true = data['emotion']\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt').to(model.device)\n",
    "\n",
    "outputs = trainer.model(**inputs)\n",
    "logits = outputs.logits\n",
    "probs = sigmoid(logits.squeeze().detach().cpu().numpy()) # apply sigmoid + threshold\n",
    "labels_pred = (probs > 0.5).astype(int)\n",
    "emotion_pred = [id2class[idx] for idx, label in enumerate(labels_pred) if label == 1.0] # turn predicted id's into actual label names\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"True emotion(s):\", emotion_true)\n",
    "print(\"Predicted emotion(s):\", \", \".join(emotion_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lang = 'eng'\n",
    "raw_data_dir = './data/public_data/'\n",
    "preprocessed_data_dir = './data/preprocessed_data/'\n",
    "repo_id = 'alxxtexxr/SemEval2025-Task11-Dataset'\n",
    "split_sizes = [0.7, 0.15, 0.15]\n",
    "assert sum(split_sizes) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to: 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # Set random seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Optionally set random seed for sklearn and Python's own random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set random seed for os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    print(f\"Random seed set to: {seed}\")\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length: 2768\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_train_track_a_00001</td>\n",
       "      <td>But not very happy.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng_train_track_a_00002</td>\n",
       "      <td>Well she's not gon na last the whole song like...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng_train_track_a_00003</td>\n",
       "      <td>She sat at her Papa's recliner sofa only to mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng_train_track_a_00004</td>\n",
       "      <td>Yes, the Oklahoma city bombing.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng_train_track_a_00005</td>\n",
       "      <td>They were dancing to Bolero.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>eng_train_track_a_02764</td>\n",
       "      <td>\"Yeah, but did you just find that?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>eng_train_track_a_02765</td>\n",
       "      <td>I did as little as possible with my right hand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>eng_train_track_a_02766</td>\n",
       "      <td>Okay that sucks, right?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>eng_train_track_a_02767</td>\n",
       "      <td>The spark leaped through his body into mine, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>eng_train_track_a_02768</td>\n",
       "      <td>He had 4 inches and 40 pounds on me and I stil...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0     eng_train_track_a_00001   \n",
       "1     eng_train_track_a_00002   \n",
       "2     eng_train_track_a_00003   \n",
       "3     eng_train_track_a_00004   \n",
       "4     eng_train_track_a_00005   \n",
       "...                       ...   \n",
       "2763  eng_train_track_a_02764   \n",
       "2764  eng_train_track_a_02765   \n",
       "2765  eng_train_track_a_02766   \n",
       "2766  eng_train_track_a_02767   \n",
       "2767  eng_train_track_a_02768   \n",
       "\n",
       "                                                   text  Anger  Fear  Joy  \\\n",
       "0                                   But not very happy.      0     0    1   \n",
       "1     Well she's not gon na last the whole song like...      0     0    1   \n",
       "2     She sat at her Papa's recliner sofa only to mo...      0     0    0   \n",
       "3                       Yes, the Oklahoma city bombing.      1     1    0   \n",
       "4                          They were dancing to Bolero.      0     0    1   \n",
       "...                                                 ...    ...   ...  ...   \n",
       "2763                 \"Yeah, but did you just find that?      0     1    0   \n",
       "2764  I did as little as possible with my right hand...      0     0    0   \n",
       "2765                            Okay that sucks, right?      1     0    0   \n",
       "2766  The spark leaped through his body into mine, a...      0     1    0   \n",
       "2767  He had 4 inches and 40 pounds on me and I stil...      0     0    1   \n",
       "\n",
       "      Sadness  Surprise  \n",
       "0           1         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           1         1  \n",
       "4           0         0  \n",
       "...       ...       ...  \n",
       "2763        0         1  \n",
       "2764        0         0  \n",
       "2765        1         0  \n",
       "2766        0         1  \n",
       "2767        0         1  \n",
       "\n",
       "[2768 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(raw_data_dir, f'train/track_a/{lang}.csv'))\n",
    "print(\"Training DF length:\", len(train_df))\n",
    "print()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF length (splitted): 1937 --> ['text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "Validation DF length: 415 --> ['text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "Testing DF length: 416 --> ['text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n",
      "Dev. DF length: 116 --> ['text', 'emotion', 'anger', 'fear', 'joy', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "emotion_col_map = {\n",
    "    'eng': { 'Anger': 'anger', 'Fear': 'fear', 'Joy': 'joy', 'Sadness': 'sad', 'Surprise': 'surprise' },\n",
    "    'deu': { 'Anger': 'wut', 'Disgust': 'ekel', 'Fear': 'angst', 'Joy': 'freude', 'Sadness': 'trauer', 'Surprise': 'Ã¼berraschung' },\n",
    "    'sun': { 'Anger': 'marah', 'Disgust': 'jijik', 'Fear': 'takut', 'Joy': 'senang', 'Sadness': 'sedih', 'Surprise': 'terkejut' },\n",
    "}\n",
    "emotion_cols = list(emotion_col_map[lang].values())\n",
    "\n",
    "empty_emotion_map = {\n",
    "    'eng': 'neutral',\n",
    "    'deu': 'neutral',\n",
    "    'sun': 'biasa',\n",
    "}\n",
    "\n",
    "# Rename emotion columns\n",
    "train_df = train_df.rename(columns=emotion_col_map[lang])\n",
    "\n",
    "# Create 'emotion' column by combining the positive emotions\n",
    "train_df['emotion'] = train_df.apply(lambda row: ', '.join([col for col in emotion_cols if row[col] == 1]), axis=1)\n",
    "train_df['emotion'] = train_df['emotion'].replace('', empty_emotion_map[lang]) # Fill empty emotion\n",
    "# print(train_df['emotion'].value_counts())\n",
    "# print()\n",
    "\n",
    "def create_stratify_col(train_df):\n",
    "    # Create 'stratify' column for stratified split\n",
    "    train_df['stratify'] = train_df['emotion']\n",
    "\n",
    "    # Identify classes with only one member\n",
    "    single_class = train_df['emotion'].value_counts()[train_df['emotion'].value_counts() == 1].index\n",
    "\n",
    "    # Assign a dummy value for the 'stratify' column for these classes\n",
    "    train_df.loc[train_df['emotion'].isin(single_class), 'stratify'] = 'dummy'\n",
    "\n",
    "create_stratify_col(train_df)\n",
    "\n",
    "# Split training DF into training and validation DFs\n",
    "if len(split_sizes) == 3:\n",
    "    train_df_, val_test_df = train_test_split(train_df[['text', 'emotion'] + emotion_cols],\n",
    "                                        train_size=split_sizes[0],\n",
    "                                        stratify=train_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "    \n",
    "    create_stratify_col(val_test_df)\n",
    "    test_size = split_sizes[-1]/(split_sizes[1] + split_sizes[-1])\n",
    "    val_df, test_df = train_test_split(val_test_df[['text', 'emotion'] + emotion_cols],\n",
    "                                        test_size=test_size,\n",
    "                                        stratify=val_test_df['stratify'],\n",
    "                                        random_state=seed)\n",
    "    \n",
    "    print(\"Training DF length (splitted):\", len(train_df_), \"-->\", train_df_.columns.tolist())\n",
    "    print(\"Validation DF length:\", len(val_df), \"-->\", val_df.columns.tolist())\n",
    "    print(\"Testing DF length:\", len(test_df), \"-->\", test_df.columns.tolist())\n",
    "\n",
    "dev_df = pd.read_csv(os.path.join(raw_data_dir, f'dev/track_a/{lang}_a.csv'))\n",
    "dev_df = dev_df.rename(columns=emotion_col_map[lang])\n",
    "dev_df['emotion'] = None\n",
    "dev_df = dev_df[['text', 'emotion'] + emotion_cols]\n",
    "print(\"Dev. DF length:\", len(dev_df), \"-->\", dev_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/preprocessed_data/eng_70_15_15\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "save_dir_name = lang + '_' + '_'.join([str(int(split_size * 100)) for split_size in split_sizes])\n",
    "save_dir = os.path.join(preprocessed_data_dir, save_dir_name)\n",
    "\n",
    "!mkdir -p $save_dir\n",
    "\n",
    "train_df_.to_csv(os.path.join(save_dir, 'train.csv'))\n",
    "val_df.to_csv(os.path.join(save_dir, 'val.csv'))\n",
    "test_df.to_csv(os.path.join(save_dir, 'test.csv'))\n",
    "\n",
    "print(\"Saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Preprocessed Data to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/alxxtexxr/SemEval2025-Task11-Dataset/commit/6a568e4fb13bc58382db8df946d00fa00c4f0e6e', commit_message='Upload folder using huggingface_hub', commit_description='', oid='6a568e4fb13bc58382db8df946d00fa00c4f0e6e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_api = HfApi()\n",
    "hf_api.upload_folder(\n",
    "    repo_id=repo_id,\n",
    "    repo_type='dataset',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo=os.path.join('preprocessed_data', save_dir_name),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alxxtexxr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
